{
  "head": {
    "name": "Alexis de Monts",
    "title_raw": "Data Engineer / Data Scientist | Expert Cloud et Data. Alexis de Monts est un ingénieur des Ponts et Chaussées, spécialisé dans la transformation numérique des entreprises grâce à ses compétences en Data Science. Avec une formation scientifique généraliste et une spécialisation en Data Science au Politecnico di Milano, il se concentre sur l'intégration de solutions Cloud et d'algorithmes de Machine Learning dans des systèmes informatiques complexes. Son expérience inclut la création d'un Data Hub pour Renault et le développement d'applications mobiles innovantes.",
    "title_generated": "Machine Learning Engineer | Expert en MLOps et Cloud",
    "title_refined": "",
    "mail": "alexis.demonts.s@gmail.com",
    "tel_raw": "07 81 37 86 80",
    "tel_refined": ""
  },
  "sections": {
    "skills": "Alexis possède une expertise approfondie dans plusieurs domaines clés. En tant que Data Engineer et Data Scientist, il maîtrise les technologies Cloud, notamment Google Cloud Platform (GCP) et Amazon Web Services (AWS). Il est également compétent en DevOps, avec une expérience dans la mise en œuvre de pipelines CI/CD et l'utilisation de Docker pour le déploiement d'applications. Ses compétences en MLOps lui permettent d'intégrer des modèles de Machine Learning dans des solutions IT, garantissant leur efficacité et leur scalabilité. En outre, il a développé des compétences en management technique, ayant dirigé des équipes de data engineers, et en optimisation des processus, notamment dans des environnements industriels. Son approche analytique et méthodique, combinée à sa capacité à travailler en équipe, lui permet de mener à bien des projets complexes et stratégiques.",
    "hobbies": "En dehors de son expertise technique, Alexis s'intéresse à divers domaines qui enrichissent sa perspective professionnelle. Il est passionné par les nouvelles technologies et l'innovation, ce qui l'incite à se tenir informé des dernières tendances en matière de Cloud et de Data Science. Alexis apprécie également les activités de plein air, telles que la randonnée et le cyclisme, qui lui permettent de se ressourcer et de maintenir un équilibre entre sa vie professionnelle et personnelle. De plus, il s'intéresse à la culture et à l'apprentissage des langues, ayant récemment appris l'italien pour s'intégrer dans un environnement académique international. Ces centres d'intérêt reflètent son ouverture d'esprit et sa volonté d'apprendre continuellement."
  },
  "experiences": [
    {
      "title_raw": "Senior Data Scientist",
      "title_refined": "",
      "company_raw": "EY",
      "company_refined": "",
      "location_raw": "Ville de Paris, Île-de-France, France",
      "location_refined": "",
      "dates_raw": "février 2023 – présent",
      "dates_refined": "",
      "description_raw": "Mission chez Renault (FLMDH – Fleet Management Data Hub). Dans le cadre de cette mission stratégique, j’ai joué un rôle central dans la modernisation et la structuration des équipes data engineering de Renault, tout en pilotant des projets clés pour accompagner la transition du groupe vers le leasing et le véhicule électrique. Contributions principales : 1. Cadrage et pilotage des équipes Data Engineer : Management d’une équipe de 5 data engineers, en assurant le cadrage des activités, la définition des priorités, et la montée en compétence des membres sur de nouveaux outils et pratiques. Mise en place d’une méthodologie de travail structurée, alignée sur les objectifs stratégiques du groupe et intégrant des outils modernes pour améliorer la productivité et la collaboration. 2. Transition vers dbt sur Cloud Run : Conception et déploiement d’une solution innovante pour dbt, utilisant un service dédié sur Cloud Run, une première dans l’écosystème Renault. Création from scratch d’un repository Git, d’une pipeline CI/CD, et d’un service Cloud Run, permettant : La gestion efficace des modèles dbt. La standardisation des pratiques data au sein de l’équipe. Collaboration avec les équipes de sécurité informatique pour garantir la conformité aux normes du groupe, et présentation des avantages de cette solution à la direction. 3. Transformation DevOps : Introduction de pratiques DevOps modernes dans un environnement encore en transition vers le cloud. Migration des processus traditionnels de data transformation vers une solution scalable et performante intégrant dbt, contribuant à l’amélioration des performances et à la réduction des temps de traitement. Formation et accompagnement des équipes internes pour assurer une adoption réussie de cette nouvelle architecture. 4. Sujets stratégiques : Talk to Data (Gemini) : Développement d’un assistant conversationnel pour démocratiser l’accès aux données auprès des équipes métiers, facilitant ainsi des décisions basées sur les données. Estimation des Valeurs Résiduelles (VR) : Création de modèles Machine Learning pour estimer les valeurs résiduelles des véhicules en leasing, en tenant compte des spécificités des véhicules électriques et thermiques. Résultats obtenus : Réussite de la transition des équipes DevOps Renault vers une solution dbt sur Cloud Run, approuvée par les équipes de sécurité et la direction technique. Amélioration notable de la qualité et de la rapidité des pipelines de données grâce à une infrastructure moderne et un workflow CI/CD automatisé. Adoption généralisée de dbt comme standard pour les projets de transformation des données, permettant une collaboration plus fluide entre les équipes. Accélération de l’intégration des données critiques pour les décisions stratégiques liées au leasing et à l’électrification. Compétences développées : Management technique : Encadrement et montée en compétence d’une équipe data engineering. DevOps et MLOps : Mise en œuvre de pipelines CI/CD modernes et transition vers des solutions cloud natives. Collaboration interservices : Coordination entre équipes métiers, sécurité informatique, et data engineers pour faire avancer des projets stratégiques complexes.",
      "description_refined": "",
      "summary": "En tant que Senior Data Scientist chez EY, j'ai modernisé les équipes data engineering de Renault, piloté la transition vers dbt sur Cloud Run, introduit des pratiques DevOps, et développé des modèles ML pour estimer les valeurs résiduelles des véhicules. Résultats : amélioration des pipelines de données et adoption généralisée de dbt.",
      "bullets": [
        "Piloté une équipe de 5 data engineers, améliorant la productivité et la collaboration.",
        "Conçu et déployé une solution dbt sur Cloud Run, standardisant les pratiques data.",
        "Introduit des pratiques DevOps modernes, réduisant les temps de traitement des données.",
        "Développé des modèles ML pour estimer les valeurs résiduelles, facilitant des décisions stratégiques."
      ],
      "weight": 0.9,
      "order": 1,
      "nb_bullets": 4
    },
    {
      "title_raw": "Co-fondateur et CTO",
      "title_refined": "",
      "company_raw": "Kadi",
      "company_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "décembre 2022 – présent",
      "dates_refined": "",
      "description_raw": "En tant que co-fondateur et CTO de Kadi, j’ai dirigé le développement d’une application mobile innovante permettant l’analyse automatique de tickets de caisse. Mon rôle a couvert à la fois la définition de l’architecture technique et la mise en œuvre de solutions basées sur l’intelligence artificielle et le cloud. Responsabilités principales : 1. Conception et déploiement de l’application mobile : Définition de l’architecture technique de l’application, en choisissant des technologies adaptées aux besoins : Flutter pour le front-end et Google Cloud Platform (GCP) pour l’infrastructure back-end. Supervision du développement, des tests et du déploiement de l’application sur le Google Play Store et l’Apple Store, garantissant une expérience utilisateur fluide. 2. Développement d’une IA pour l’analyse des tickets de caisse : Entraînement et déploiement d’un modèle Faster R-CNN pour détecter automatiquement les tickets de caisse dans des images et extraire les données pertinentes. Mise en production sur Google App Engine, assurant une scalabilité et une haute disponibilité des services. 3. Création de workflows de données évolutifs : Mise en place de pipelines de données automatisés à l’aide de Cloud Functions, Firestore, et BigQuery pour stocker, traiter et analyser les données utilisateur. Intégration des bonnes pratiques MLOps, incluant la surveillance des performances, la gestion des versions du modèle et l’automatisation des mises à jour. 4. Optimisation des pipelines de bout en bout : Développement de pipelines fiables et performants pour traiter les données en temps réel, de la réception des images au stockage et à la restitution des résultats aux utilisateurs. Résultats : Déploiement réussi de l’application en version bêta, validée par une communauté d’utilisateurs sur les deux principales plateformes mobiles. Compétences développées : Leadership technique : Coordination d’une équipe technique et supervision des choix stratégiques en matière de technologies. Machine Learning appliqué : Développement de solutions basées sur des modèles de détection d’objets et leur mise en production dans des environnements cloud. Cloud computing : Expertise dans l’utilisation de GCP pour développer des systèmes évolutifs et performants. MLOps : Application des principes de DevOps au machine learning pour garantir la fiabilité et la pérennité des modèles en production. Développement mobile : Maîtrise de Flutter et des exigences spécifiques au déploiement sur Google Play et Apple Store. Impact et résultats : Création d’une application mobile intuitive répondant à un besoin concret : simplifier la gestion des tickets de caisse pour les utilisateurs. Déploiement d’une infrastructure cloud robuste, capable de gérer des flux de données en temps réel avec une latence minimale. Mise en œuvre d’un modèle d’IA performant et innovant pour extraire automatiquement des informations structurées à partir de données brutes.",
      "description_refined": "",
      "summary": "En tant que co-fondateur et CTO de Kadi, j'ai développé une application mobile innovante pour l'analyse automatique des tickets de caisse, intégrant IA et cloud. J'ai supervisé l'architecture technique, le déploiement sur les stores, et créé des pipelines de données évolutifs, garantissant une expérience utilisateur fluide et performante.",
      "bullets": [
        "Développé une IA pour extraire des données de tickets de caisse, déployée sur Google App Engine.",
        "Créé des pipelines de données automatisés, garantissant scalabilité et haute disponibilité.",
        "Supervisé le déploiement d'une application mobile sur Google Play et Apple Store, validée par des utilisateurs."
      ],
      "weight": 0.8,
      "order": 2,
      "nb_bullets": 3
    },
    {
      "title_raw": "Ingénieur en Transformation Digitale",
      "title_refined": "",
      "company_raw": "Blispac",
      "company_refined": "",
      "location_raw": "Balagny-sur-Thérain (60)",
      "location_refined": "",
      "dates_raw": "février 2022 – septembre 2022",
      "dates_refined": "",
      "description_raw": "Au sein de cette entreprise familiale spécialisée dans la production de prothèses médicales, j’ai conduit plusieurs projets stratégiques visant à moderniser et optimiser les processus internes. Responsabilités principales : 1. Digitalisation de l’entreprise : Refonte et structuration des bases de données existantes en SQL pour centraliser et sécuriser les informations critiques. Développement d’outils facilitant l’accès aux données pour les différents départements de l’entreprise. Mise à jour de l’ERP : Analyse des besoins métiers et adaptation de l’ERP pour mieux répondre aux exigences opérationnelles. Intégration de nouvelles fonctionnalités pour améliorer la traçabilité des produits et le suivi des commandes. 2. Optimisation des processus de fabrication : Conception et implémentation d’un algorithme génétique pour optimiser le positionnement des pièces dans les moules, réduisant ainsi les pertes de matériaux et les temps de cycle. Résultats : Amélioration significative de l’efficacité des lignes de production et réduction des coûts associés aux déchets. 3. Automatisation des bancs de test pour prothèses médicales : Développement d’un banc de test automatisé pour les prothèses de hanches, capable de générer des courbes CAM conformes aux normes ISO. Objectifs atteints : Minimisation du “jerk” (accélération brusque) pour garantir des tests fiables et conformes aux standards. Réduction du temps nécessaire aux validations des prototypes grâce à l’automatisation des processus. Compétences développées : Ingénierie digitale : Maîtrise de la structuration des bases de données et des systèmes ERP dans un environnement industriel. Recherche opérationnelle (RO) et optimisation : Utilisation d’algorithmes évolutifs pour résoudre des problèmes complexes liés à la fabrication. Automatisation industrielle : Développement et mise en œuvre de solutions techniques pour améliorer la qualité et l’efficacité des processus de tests. Gestion de projet : Coordination entre les différents services de l’entreprise pour garantir l’alignement des solutions avec les objectifs stratégiques.",
      "description_refined": "",
      "summary": "En tant qu'ingénieur en transformation digitale chez Blispac, j'ai modernisé les processus internes en digitalisant les bases de données, optimisant la fabrication avec un algorithme génétique, et automatisant les tests de prothèses. Ces initiatives ont amélioré l'efficacité, réduit les coûts et garanti la conformité aux normes ISO.",
      "bullets": [
        "Digitalisé les bases de données en SQL, centralisant les informations critiques pour l'entreprise.",
        "Optimisé le positionnement des pièces, réduisant les pertes de matériaux et les temps de cycle.",
        "Automatisé les tests de prothèses, garantissant des validations conformes et fiables aux normes ISO."
      ],
      "weight": 0.6,
      "order": 3,
      "nb_bullets": 3
    },
    {
      "title_raw": "Analyste de Marché",
      "title_refined": "",
      "company_raw": "Total",
      "company_refined": "",
      "location_raw": "Paris, France",
      "location_refined": "",
      "dates_raw": "février 2020 – juillet 2020",
      "dates_refined": "",
      "description_raw": "Au sein de la direction GRP de TotalEnergies, j’ai contribué à l’analyse stratégique des marchés énergétiques mondiaux, en travaillant sur des projets de modélisation et de suivi des dynamiques énergétiques à long terme. Responsabilités principales : 1. Total Energy Outlook : Participation à l’élaboration du Total Energy Outlook, une publication stratégique qui projette l’évolution des marchés énergétiques mondiaux à l’horizon 2050. Travail collaboratif avec une équipe de 10 analystes, combinant expertise sectorielle et modélisation avancée. Production de rapports et d’analyses prospectives pour éclairer les décisions stratégiques du Comex du groupe. 2. Business Reviews : Rédaction et présentation de Business Reviews sur les marchés du gaz naturel liquéfié (GNL) et de l’électricité. Analyse des tendances clés, identification des opportunités, et recommandations pour le développement des activités du groupe. 3. Modélisation et innovation : Développement d’un algorithme en Python, combiné à des pipelines de données, pour suivre en temps réel les tankers GNL à partir des bases de données IHS. Création d’indicateurs inédits, inspirés des méthodologies du marché pétrolier, appliqués pour la première fois au marché GNL : Repositionnement des navires. Analyse des trajets ballast/laden (chargés ou à vide). Utilisation de Pandas pour le traitement des données et de Power BI pour la visualisation, facilitant la prise de décision stratégique. Résultats notables : Mise en place d’une approche innovante pour le suivi des flux de GNL, permettant à TotalEnergies de mieux comprendre et anticiper les dynamiques du marché GNL.",
      "description_refined": "",
      "summary": "En tant qu'analyste de marché chez Total, j'ai contribué à l'analyse stratégique des marchés énergétiques, participé à l'élaboration du Total Energy Outlook, rédigé des Business Reviews sur le GNL et l'électricité, et développé un algorithme en Python pour suivre les tankers GNL, améliorant ainsi la compréhension des dynamiques du marché.",
      "bullets": [
        "Développé un algorithme en Python pour suivre en temps réel les tankers GNL, améliorant l'analyse.",
        "Contribué à l'élaboration du Total Energy Outlook, éclairant les décisions stratégiques du Comex."
      ],
      "weight": 0.5,
      "order": 4,
      "nb_bullets": 2
    }
  ],
  "education": [
    {
      "degree_raw": "Diplôme d’ingénieur",
      "degree_refined": "",
      "institution_raw": "École des Ponts ParisTech",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2017 – 2021",
      "dates_refined": "",
      "description_raw": "Durant mon cursus à l’École des Ponts ParisTech, j’ai bénéficié d’une formation scientifique et technique de haut niveau, complétée par des enseignements spécialisés en supply chain et en machine learning. 1. Tronc commun scientifique (1ère année) : La première année était dédiée à l’acquisition de bases solides dans les disciplines fondamentales de l’ingénierie : Mathématiques appliquées : approfondissement des concepts d’analyse, d’algèbre linéaire et de probabilités, essentiels pour la modélisation et la résolution de problèmes complexes. Physique : étude des principes de la mécanique, de la thermodynamique et de l’électromagnétisme, permettant de comprendre les phénomènes physiques sous-jacents aux systèmes ingénieriques. Informatique : introduction aux structures de données, aux algorithmes et aux bases de la programmation, compétences cruciales pour le développement d’outils numériques. Sciences de l’ingénieur : notions fondamentales en mécanique des structures et des matériaux, offrant une compréhension des comportements mécaniques des ouvrages et des matériaux utilisés. 2. Spécialisation en Supply Chain et Machine Learning (2ème et 3ème années) : Après le tronc commun, j’ai orienté ma formation vers des domaines spécifiques en choisissant des cours et des projets liés à la supply chain et au machine learning.",
      "description_generated": "Ma formation en ingénierie m’a permis d’acquérir des compétences solides en mathématiques appliquées, programmation et machine learning. J’ai développé une expertise en modélisation et en résolution de problèmes complexes, essentielle pour concevoir et déployer des modèles de Machine Learning et Deep Learning dans un environnement collaboratif.",
      "description_refined": "",
      "summary": "Formation d'ingénieur à l'École des Ponts ParisTech, alliant sciences fondamentales et spécialisation en supply chain et machine learning. Acquisition de compétences en mathématiques, physique, informatique et sciences de l'ingénieur, suivie d'une orientation vers des projets spécifiques en logistique et apprentissage automatique.",
      "weight": 0.8,
      "order": 1,
      "nb_mots": 44
    },
    {
      "degree_raw": "Master 2 en Mathematical Engineering",
      "degree_refined": "",
      "institution_raw": "Politecnico di Milano",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2020 – 2021",
      "dates_refined": "",
      "description_raw": "Durant cette année de spécialisation en ingénierie mathématique, j’ai approfondi mes connaissances en mathématiques appliquées, finance computationnelle, machine learning et supply chain management, tout en apprenant l’italien pour m’intégrer pleinement à l’environnement académique et culturel. Cours principaux suivis : 1. Computational Finance : Ce cours portait sur les méthodes quantitatives avancées pour décrire la dynamique des marchés financiers, évaluer et couvrir des produits dérivés, et résoudre des problèmes d’investissement optimal. 2. Machine Learning : Ce cours proposait une base solide en apprentissage supervisé, apprentissage par renforcement et algorithmes d’extraction de connaissances, avec des applications variées.",
      "description_generated": "Ma formation en ingénierie mathématique m'a permis d'acquérir des compétences avancées en machine learning, incluant l'apprentissage supervisé et par renforcement, ainsi qu'une solide compréhension des méthodes quantitatives. Ces connaissances sont essentielles pour concevoir, entraîner et déployer des modèles de machine learning dans un environnement collaboratif et innovant.",
      "description_refined": "",
      "summary": "Master 2 en ingénierie mathématique au Politecnico di Milano, 2020-2021. Spécialisation en mathématiques appliquées, finance computationnelle, machine learning et supply chain management. Cours clés : méthodes quantitatives en finance et apprentissage supervisé. Apprentissage de l’italien pour une intégration culturelle et académique.",
      "weight": 1.0,
      "order": 2,
      "nb_mots": 50
    },
    {
      "degree_raw": "Classe préparatoire scientifique",
      "degree_refined": "",
      "institution_raw": "Collège Stanislas Paris",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2015 – 2017",
      "dates_refined": "",
      "description_raw": "Durant ces deux années, j’ai suivi une formation académique exigeante en classes préparatoires, préparant aux concours des grandes écoles d’ingénieurs.",
      "description_generated": "Ma formation en classes préparatoires scientifiques m'a permis d'acquérir des compétences solides en mathématiques et en algorithmique, essentielles pour concevoir et déployer des modèles de Machine Learning, tout en développant une rigueur et une capacité d'analyse adaptées aux défis en IA.",
      "description_refined": "",
      "summary": "Formation académique rigoureuse en classe préparatoire scientifique, axée sur la préparation aux concours des grandes écoles d'ingénieurs, acquise sur deux ans au Collège Stanislas à Paris.",
      "weight": 0.6,
      "order": 3,
      "nb_mots": 38
    }
  ],
  "competences": {
    "Compétences techniques": [
      "À compléter"
    ]
  },
  "skills_raw": "Alexis possède une expertise approfondie dans plusieurs domaines clés. En tant que Data Engineer et Data Scientist, il maîtrise les technologies Cloud, notamment Google Cloud Platform (GCP) et Amazon Web Services (AWS). Il est également compétent en DevOps, avec une expérience dans la mise en œuvre de pipelines CI/CD et l'utilisation de Docker pour le déploiement d'applications. Ses compétences en MLOps lui permettent d'intégrer des modèles de Machine Learning dans des solutions IT, garantissant leur efficacité et leur scalabilité. En outre, il a développé des compétences en management technique, ayant dirigé des équipes de data engineers, et en optimisation des processus, notamment dans des environnements industriels. Son approche analytique et méthodique, combinée à sa capacité à travailler en équipe, lui permet de mener à bien des projets complexes et stratégiques.",
  "langues": [],
  "hobbies_raw": "En dehors de son expertise technique, Alexis s'intéresse à divers domaines qui enrichissent sa perspective professionnelle. Il est passionné par les nouvelles technologies et l'innovation, ce qui l'incite à se tenir informé des dernières tendances en matière de Cloud et de Data Science. Alexis apprécie également les activités de plein air, telles que la randonnée et le cyclisme, qui lui permettent de se ressourcer et de maintenir un équilibre entre sa vie professionnelle et personnelle. De plus, il s'intéresse à la culture et à l'apprentissage des langues, ayant récemment appris l'italien pour s'intégrer dans un environnement académique international. Ces centres d'intérêt reflètent son ouverture d'esprit et sa volonté d'apprendre continuellement.",
  "hobbies_refined": "",
  "job_raw": "iche de Poste – Machine Learning Engineer\n\n📍 Localisation : Paris, France (Hybrid)\n\n📅 Type de Contrat : CDI\n\n📊 Expérience : 3+ ans\n\n💰 Salaire : 55k - 75k € selon expérience\n\n💼 Secteur : Tech / IA / Data\n\n\n🚀 À propos de nous\n\nNous sommes une startup innovante spécialisée dans l’intelligence artificielle et le traitement des données à grande échelle. Nous développons des solutions de Machine Learning et Deep Learning pour optimiser la prise de décision et automatiser des processus complexes dans divers secteurs (finance, retail, industrie, santé…).\n\nNotre équipe est composée de passionnés de l’IA et de la data, avec une forte culture d’innovation et un environnement de travail dynamique.\n\n🎯 Missions\n\nEn tant que Machine Learning Engineer, vous aurez pour mission de :\n\t•\tConcevoir, entraîner et déployer des modèles de Machine Learning et Deep Learning adaptés aux besoins métier.\n\t•\tTravailler avec des data scientists pour industrialiser les modèles et les intégrer aux produits en production.\n\t•\tOptimiser les pipelines de données et les modèles pour améliorer la performance et la scalabilité.\n\t•\tDévelopper des API et des microservices pour exposer les modèles ML en production.\n\t•\tMonitorer et améliorer la qualité des modèles en continu (MLOps).\n\t•\tCollaborer avec les équipes DevOps et Data Engineering pour assurer la robustesse des infrastructures ML.\n\t•\tDocumenter et partager les bonnes pratiques en ingénierie ML.\n\n🛠️ Stack Technique\n    •\tLangages : Python (TensorFlow, PyTorch, Scikit-Learn), SQL\n    •\tCloud & DevOps : AWS (SageMaker, Lambda, S3), GCP, Docker, Kubernetes\n    •\tBig Data : Spark, Dask, Apache Beam\n    •\tMLOps : MLflow, DVC, Kubeflow, Airflow\n    •\tDéveloppement : FastAPI, Flask, Git, CI/CD\n\n🎓 Profil recherché\n\t•\tDiplôme en Informatique, Mathématiques appliquées, Intelligence Artificielle ou équivalent.\n\t•\tExpérience confirmée en développement et déploiement de modèles ML en production.\n\t•\tBonne maîtrise des pipelines de données et des architectures distribuées.\n\t•\tExpérience avec les outils MLOps et le déploiement de modèles à l’échelle.\n\t•\tCapacité à collaborer avec des équipes pluridisciplinaires (Data Scientists, DevOps, Software Engineers).\n\t•\tEsprit analytique, curiosité et passion pour l’IA et la Data Science.\n\n💡 Pourquoi nous rejoindre ?\n\n✅ Projets innovants en IA et ML\n✅ Culture d’entreprise orientée innovation et partage\n✅ Technologies modernes et stack technique avancée\n✅ Équipe bienveillante et dynamique\n✅ Flexibilité (hybride) et package attractif\n\n📩 Comment postuler ?\n\nEnvoyez votre CV et une courte présentation à recrutement@startupAI.com. 🚀",
  "job_refined": "Nous recherchons un Machine Learning Engineer expérimenté (3+ ans) pour rejoindre notre startup innovante à Paris, spécialisée en IA et traitement de données. Vous serez responsable de concevoir, entraîner et déployer des modèles de Machine Learning et Deep Learning, en collaboration avec des data scientists et des équipes DevOps. Une maîtrise des outils MLOps et des pipelines de données est essentielle. Le poste offre un salaire de 55k à 75k € et un environnement de travail hybride. Rejoignez-nous pour travailler sur des projets innovants et contribuer à une culture d’innovation dynamique. Postulez à recrutement@startupAI.com."
}