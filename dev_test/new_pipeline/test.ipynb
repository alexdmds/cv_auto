{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nous recherchons un Machine Learning Engineer pour rejoindre notre startup innovante à Paris. En CDI, avec un salaire compris entre 55k et 75k €, vous serez responsable de la conception, l'entraînement et le déploiement de modèles ML et Deep Learning. Vous travaillerez en étroite collaboration avec data scientists et équipes DevOps pour optimiser des pipelines de données et intégrer des solutions au sein de divers secteurs comme la finance et le retail. Vous maîtrisez Python, AWS, et les outils MLOps. Si vous avez une passion pour l'IA et un esprit analytique, rejoignez-nous pour des projets innovants.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from data_structures import GlobalState\n",
    "\n",
    "state_path = \"result_state.json\"\n",
    "with open(state_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Création d'une instance de GlobalState à partir du JSON\n",
    "global_state = GlobalState.from_json(data)  # job_summary est optionnel\n",
    "\n",
    "#job summary\n",
    "print(global_state.job_refined)\n",
    "\n",
    "# Création du State pour prioritize_exp\n",
    "state = {\n",
    "    \"job_summary\": global_state.job_refined,\n",
    "    \"markdown_choice\": \"\",\n",
    "    \"experiences_raw\": global_state.experiences,\n",
    "    \"experiences_weighted\": [],\n",
    "    \"experiences_bullets\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Analyse des Expériences\n",
       "\n",
       "## Senior Data Scientist chez EY\n",
       "- Poids: 1\n",
       "- Ordre: 1\n",
       "- Justification: Cette expérience démontre une maîtrise en développement de modèles Machine Learning et en optimisation des pipelines de données, essentiels pour le poste.\n",
       "\n",
       "## Co-fondateur et CTO chez Kadi\n",
       "- Poids: 1\n",
       "- Ordre: 2\n",
       "- Justification: Le rôle inclut la supervision de l'architecture et du déploiement d'applications intégrant de l'IA, ce qui est directement pertinent pour les responsabilités décrites dans le poste.\n",
       "\n",
       "## Ingénieur en Transformation Digitale chez Blispac\n",
       "- Poids: 0.8\n",
       "- Ordre: 3\n",
       "- Justification: Bien que moins centré sur le Machine Learning, ce rôle a impliqué l'optimisation de processus via des algorithmes, ce qui est pertinent pour le développement de solutions innovantes.\n",
       "\n",
       "## Analyste de Marché chez Total\n",
       "- Poids: 0.6\n",
       "- Ordre: 4\n",
       "- Justification: Cette expérience montre des compétences en analyse de données avec Python, mais elle est moins axée sur le Machine Learning comparée aux autres expériences sélectionnées."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from prioritize_exp import generate_markdown_choice\n",
    "\n",
    "markdown_choice = generate_markdown_choice(state)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(markdown_choice[\"markdown_choice\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Détails de l'expérience pondérée ===\n",
      "Titre: Senior Data Scientist\n",
      "Entreprise: EY\n",
      "Lieu: Ville de Paris, Île-de-France, France\n",
      "Dates: février 2023 – présent\n",
      "Description: Mission chez Renault (FLMDH – Fleet Management Data Hub). Dans le cadre de cette mission stratégique, j’ai joué un rôle central dans la modernisation et la structuration des équipes data engineering de Renault, tout en pilotant des projets clés pour accompagner la transition du groupe vers le leasing et le véhicule électrique. Contributions principales : 1. Cadrage et pilotage des équipes Data Engineer : Management d’une équipe de 5 data engineers, en assurant le cadrage des activités, la définition des priorités, et la montée en compétence des membres sur de nouveaux outils et pratiques. Mise en place d’une méthodologie de travail structurée, alignée sur les objectifs stratégiques du groupe et intégrant des outils modernes pour améliorer la productivité et la collaboration. 2. Transition vers dbt sur Cloud Run : Conception et déploiement d’une solution innovante pour dbt, utilisant un service dédié sur Cloud Run, une première dans l’écosystème Renault. Création from scratch d’un repository Git, d’une pipeline CI/CD, et d’un service Cloud Run, permettant : La gestion efficace des modèles dbt. La standardisation des pratiques data au sein de l’équipe. Collaboration avec les équipes de sécurité informatique pour garantir la conformité aux normes du groupe, et présentation des avantages de cette solution à la direction. 3. Transformation DevOps : Introduction de pratiques DevOps modernes dans un environnement encore en transition vers le cloud. Migration des processus traditionnels de data transformation vers une solution scalable et performante intégrant dbt, contribuant à l’amélioration des performances et à la réduction des temps de traitement. Formation et accompagnement des équipes internes pour assurer une adoption réussie de cette nouvelle architecture. 4. Sujets stratégiques : Talk to Data (Gemini) : Développement d’un assistant conversationnel pour démocratiser l’accès aux données auprès des équipes métiers, facilitant ainsi des décisions basées sur les données. Estimation des Valeurs Résiduelles (VR) : Création de modèles Machine Learning pour estimer les valeurs résiduelles des véhicules en leasing, en tenant compte des spécificités des véhicules électriques et thermiques. Résultats obtenus : Réussite de la transition des équipes DevOps Renault vers une solution dbt sur Cloud Run, approuvée par les équipes de sécurité et la direction technique. Amélioration notable de la qualité et de la rapidité des pipelines de données grâce à une infrastructure moderne et un workflow CI/CD automatisé. Adoption généralisée de dbt comme standard pour les projets de transformation des données, permettant une collaboration plus fluide entre les équipes. Accélération de l’intégration des données critiques pour les décisions stratégiques liées au leasing et à l’électrification. Compétences développées : Management technique : Encadrement et montée en compétence d’une équipe data engineering. DevOps et MLOps : Mise en œuvre de pipelines CI/CD modernes et transition vers des solutions cloud natives. Collaboration interservices : Coordination entre équipes métiers, sécurité informatique, et data engineers pour faire avancer des projets stratégiques complexes.\n",
      "Résumé: En tant que Senior Data Scientist chez EY, j'ai modernisé les équipes data engineering de Renault, piloté la transition vers dbt sur Cloud Run, introduit des pratiques DevOps, et développé des modèles Machine Learning pour améliorer les décisions sur le leasing et l'électrification. Résultats : meilleure qualité des données et collaboration optimisée.\n",
      "Nombre de bullets: 0\n",
      "Ordre: 1\n",
      "Bullets générés: []\n",
      "Poids: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Mise à jour du state avec le markdown généré\n",
    "state[\"markdown_choice\"] = markdown_choice[\"markdown_choice\"]\n",
    "\n",
    "# Création d'un WorkerWeightState pour la première expérience\n",
    "worker_weight_state = {\n",
    "    \"experience\": state[\"experiences_raw\"][0],\n",
    "    \"markdown_choice\": state[\"markdown_choice\"]\n",
    "}\n",
    "\n",
    "# Appel du worker de pondération\n",
    "from prioritize_exp import weight_experiences\n",
    "weighted_exp = weight_experiences(worker_weight_state)\n",
    "\n",
    "# Affichage des résultats\n",
    "exp = weighted_exp['experiences_weighted'][0]\n",
    "print(\"=== Détails de l'expérience pondérée ===\")\n",
    "print(f\"Titre: {exp.title_raw}\")\n",
    "print(f\"Entreprise: {exp.company_raw}\")\n",
    "print(f\"Lieu: {exp.location_raw}\")\n",
    "print(f\"Dates: {exp.dates_raw}\")\n",
    "print(f\"Description: {exp.description_raw}\")\n",
    "print(f\"Résumé: {exp.summary}\")\n",
    "print(f\"Nombre de bullets: {exp.nb_bullets}\")\n",
    "print(f\"Ordre: {exp.order}\")\n",
    "print(f\"Bullets générés: {exp.bullets}\")\n",
    "print(f\"Poids: {exp.weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Bullets générés ===\n",
      "Titre: Senior Data Scientist\n",
      "Entreprise: EY\n",
      "\n",
      "Bullets:\n"
     ]
    }
   ],
   "source": [
    "# Création d'un WorkerBulletsState pour la première expérience\n",
    "worker_bullets_state = {\n",
    "    \"experience\": exp,\n",
    "    \"job_summary\": state[\"job_summary\"]\n",
    "}\n",
    "\n",
    "# Appel du worker de génération de bullets\n",
    "from prioritize_exp import generate_bullets\n",
    "bullets_exp = generate_bullets(worker_bullets_state)\n",
    "\n",
    "# Affichage des résultats\n",
    "exp_with_bullets = bullets_exp['experiences_bullets'][0]\n",
    "print(\"\\n=== Bullets générés ===\")\n",
    "print(f\"Titre: {exp_with_bullets.title_raw}\")\n",
    "print(f\"Entreprise: {exp_with_bullets.company_raw}\")\n",
    "print(\"\\nBullets:\")\n",
    "for bullet in exp_with_bullets.bullets:\n",
    "    print(f\"• {bullet}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
