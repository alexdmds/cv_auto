{
  "head": {
    "name": "Alexis de Monts",
    "title_raw": "Data Engineer / Data Scientist | Expert Cloud et Data. Alexis de Monts est un ingénieur des Ponts et Chaussées, spécialisé dans la transformation numérique des entreprises grâce à ses compétences en Data Science. Avec une formation scientifique généraliste et une spécialisation en Data Science au Politecnico di Milano, il se concentre sur l'intégration de solutions Cloud et d'algorithmes de Machine Learning dans des systèmes informatiques complexes. Son expérience inclut la création d'un Data Hub pour Renault et le développement d'applications mobiles innovantes.",
    "title_generated": "Data Tech Lead | Expert en Data Engineering et DevOps",
    "title_refined": "",
    "mail": "alexis.demonts.s@gmail.com",
    "tel_raw": "07 81 37 86 80",
    "tel_refined": ""
  },
  "sections": {
    "skills": "Alexis possède une expertise approfondie dans plusieurs domaines clés. En tant que Data Engineer et Data Scientist, il maîtrise les technologies Cloud, notamment Google Cloud Platform (GCP) et Amazon Web Services (AWS). Il est également compétent en DevOps, avec une expérience dans la mise en œuvre de pipelines CI/CD et l'utilisation de Docker pour le déploiement d'applications. Ses compétences en MLOps lui permettent d'intégrer des modèles de Machine Learning dans des solutions IT, garantissant leur efficacité et leur scalabilité. En outre, il a développé des compétences en management technique, ayant dirigé des équipes de data engineers, et en optimisation des processus, notamment dans des environnements industriels. Son approche analytique et méthodique, combinée à sa capacité à travailler en équipe, lui permet de mener à bien des projets complexes et stratégiques.",
    "hobbies": "En dehors de son expertise technique, Alexis s'intéresse à divers domaines qui enrichissent sa perspective professionnelle. Il est passionné par les nouvelles technologies et l'innovation, ce qui l'incite à se tenir informé des dernières tendances en matière de Cloud et de Data Science. Alexis apprécie également les activités de plein air, telles que la randonnée et le cyclisme, qui lui permettent de se ressourcer et de maintenir un équilibre entre sa vie professionnelle et personnelle. De plus, il s'intéresse à la culture et à l'apprentissage des langues, ayant récemment appris l'italien pour s'intégrer dans un environnement académique international. Ces centres d'intérêt reflètent son ouverture d'esprit et sa volonté d'apprendre continuellement."
  },
  "experiences": [
    {
      "title_raw": "Co-fondateur et CTO",
      "title_refined": "",
      "company_raw": "Kadi",
      "company_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "décembre 2022 – présent",
      "dates_refined": "",
      "description_raw": "En tant que co-fondateur et CTO de Kadi, j’ai dirigé le développement d’une application mobile innovante permettant l’analyse automatique de tickets de caisse. Mon rôle a couvert à la fois la définition de l’architecture technique et la mise en œuvre de solutions basées sur l’intelligence artificielle et le cloud. Responsabilités principales : 1. Conception et déploiement de l’application mobile : Définition de l’architecture technique de l’application, en choisissant des technologies adaptées aux besoins : Flutter pour le front-end et Google Cloud Platform (GCP) pour l’infrastructure back-end. Supervision du développement, des tests et du déploiement de l’application sur le Google Play Store et l’Apple Store, garantissant une expérience utilisateur fluide. 2. Développement d’une IA pour l’analyse des tickets de caisse : Entraînement et déploiement d’un modèle Faster R-CNN pour détecter automatiquement les tickets de caisse dans des images et extraire les données pertinentes. Mise en production sur Google App Engine, assurant une scalabilité et une haute disponibilité des services. 3. Création de workflows de données évolutifs : Mise en place de pipelines de données automatisés à l’aide de Cloud Functions, Firestore, et BigQuery pour stocker, traiter et analyser les données utilisateur. Intégration des bonnes pratiques MLOps, incluant la surveillance des performances, la gestion des versions du modèle et l’automatisation des mises à jour. 4. Optimisation des pipelines de bout en bout : Développement de pipelines fiables et performants pour traiter les données en temps réel, de la réception des images au stockage et à la restitution des résultats aux utilisateurs. Résultats : Déploiement réussi de l’application en version bêta, validée par une communauté d’utilisateurs sur les deux principales plateformes mobiles. Compétences développées : Leadership technique : Coordination d’une équipe technique et supervision des choix stratégiques en matière de technologies. Machine Learning appliqué : Développement de solutions basées sur des modèles de détection d’objets et leur mise en production dans des environnements cloud. Cloud computing : Expertise dans l’utilisation de GCP pour développer des systèmes évolutifs et performants. MLOps : Application des principes de DevOps au machine learning pour garantir la fiabilité et la pérennité des modèles en production. Développement mobile : Maîtrise de Flutter et des exigences spécifiques au déploiement sur Google Play et Apple Store. Impact et résultats : Création d’une application mobile intuitive répondant à un besoin concret : simplifier la gestion des tickets de caisse pour les utilisateurs. Déploiement d’une infrastructure cloud robuste, capable de gérer des flux de données en temps réel avec une latence minimale. Mise en œuvre d’un modèle d’IA performant et innovant pour extraire automatiquement des informations structurées à partir de données brutes.",
      "description_refined": "",
      "summary": "En tant que co-fondateur et CTO de Kadi, j'ai dirigé le développement d'une application mobile innovante pour l'analyse automatique de tickets de caisse, intégrant des solutions d'IA et de cloud. J'ai supervisé l'architecture technique, le déploiement sur les stores, et optimisé des pipelines de données pour une expérience utilisateur fluide.",
      "bullets": [
        "Dirigé le développement d'une application mobile, déployée sur Google Play et Apple Store.",
        "Développé un modèle IA pour l'analyse de tickets, assurant scalabilité et haute disponibilité.",
        "Créé des pipelines de données automatisés, intégrant MLOps pour fiabilité et performance.",
        "Optimisé des workflows de données en temps réel, améliorant l'expérience utilisateur."
      ],
      "weight": 1.0,
      "order": 1,
      "nb_bullets": 4
    },
    {
      "title_raw": "Senior Data Scientist",
      "title_refined": "",
      "company_raw": "EY",
      "company_refined": "",
      "location_raw": "Ville de Paris, Île-de-France, France",
      "location_refined": "",
      "dates_raw": "février 2023 – présent",
      "dates_refined": "",
      "description_raw": "Mission chez Renault (FLMDH – Fleet Management Data Hub). Dans le cadre de cette mission stratégique, j’ai joué un rôle central dans la modernisation et la structuration des équipes data engineering de Renault, tout en pilotant des projets clés pour accompagner la transition du groupe vers le leasing et le véhicule électrique. Contributions principales : 1. Cadrage et pilotage des équipes Data Engineer : Management d’une équipe de 5 data engineers, en assurant le cadrage des activités, la définition des priorités, et la montée en compétence des membres sur de nouveaux outils et pratiques. Mise en place d’une méthodologie de travail structurée, alignée sur les objectifs stratégiques du groupe et intégrant des outils modernes pour améliorer la productivité et la collaboration. 2. Transition vers dbt sur Cloud Run : Conception et déploiement d’une solution innovante pour dbt, utilisant un service dédié sur Cloud Run, une première dans l’écosystème Renault. Création from scratch d’un repository Git, d’une pipeline CI/CD, et d’un service Cloud Run, permettant : La gestion efficace des modèles dbt. La standardisation des pratiques data au sein de l’équipe. Collaboration avec les équipes de sécurité informatique pour garantir la conformité aux normes du groupe, et présentation des avantages de cette solution à la direction. 3. Transformation DevOps : Introduction de pratiques DevOps modernes dans un environnement encore en transition vers le cloud. Migration des processus traditionnels de data transformation vers une solution scalable et performante intégrant dbt, contribuant à l’amélioration des performances et à la réduction des temps de traitement. Formation et accompagnement des équipes internes pour assurer une adoption réussie de cette nouvelle architecture. 4. Sujets stratégiques : Talk to Data (Gemini) : Développement d’un assistant conversationnel pour démocratiser l’accès aux données auprès des équipes métiers, facilitant ainsi des décisions basées sur les données. Estimation des Valeurs Résiduelles (VR) : Création de modèles Machine Learning pour estimer les valeurs résiduelles des véhicules en leasing, en tenant compte des spécificités des véhicules électriques et thermiques. Résultats obtenus : Réussite de la transition des équipes DevOps Renault vers une solution dbt sur Cloud Run, approuvée par les équipes de sécurité et la direction technique. Amélioration notable de la qualité et de la rapidité des pipelines de données grâce à une infrastructure moderne et un workflow CI/CD automatisé. Adoption généralisée de dbt comme standard pour les projets de transformation des données, permettant une collaboration plus fluide entre les équipes. Accélération de l’intégration des données critiques pour les décisions stratégiques liées au leasing et à l’électrification. Compétences développées : Management technique : Encadrement et montée en compétence d’une équipe data engineering. DevOps et MLOps : Mise en œuvre de pipelines CI/CD modernes et transition vers des solutions cloud natives. Collaboration interservices : Coordination entre équipes métiers, sécurité informatique, et data engineers pour faire avancer des projets stratégiques complexes.",
      "description_refined": "",
      "summary": "En tant que Senior Data Scientist chez EY, j'ai modernisé les équipes data engineering de Renault, piloté la transition vers dbt sur Cloud Run, introduit des pratiques DevOps, et développé des modèles de Machine Learning pour estimer les valeurs résiduelles des véhicules. Résultats : amélioration des pipelines de données et adoption généralisée de dbt.",
      "bullets": [
        "Piloté une équipe de 5 data engineers, améliorant la productivité et la collaboration.",
        "Développé une solution dbt sur Cloud Run, standardisant les pratiques data au sein de l'équipe.",
        "Introduit des pratiques DevOps modernes, réduisant les temps de traitement des données.",
        "Créé des modèles ML pour estimer les valeurs résiduelles, facilitant des décisions stratégiques."
      ],
      "weight": 0.9,
      "order": 2,
      "nb_bullets": 4
    },
    {
      "title_raw": "Ingénieur en Transformation Digitale",
      "title_refined": "",
      "company_raw": "Blispac",
      "company_refined": "",
      "location_raw": "Balagny-sur-Thérain (60)",
      "location_refined": "",
      "dates_raw": "février 2022 – septembre 2022",
      "dates_refined": "",
      "description_raw": "Au sein de cette entreprise familiale spécialisée dans la production de prothèses médicales, j’ai conduit plusieurs projets stratégiques visant à moderniser et optimiser les processus internes. Responsabilités principales : 1. Digitalisation de l’entreprise : Refonte et structuration des bases de données existantes en SQL pour centraliser et sécuriser les informations critiques. Développement d’outils facilitant l’accès aux données pour les différents départements de l’entreprise. Mise à jour de l’ERP : Analyse des besoins métiers et adaptation de l’ERP pour mieux répondre aux exigences opérationnelles. Intégration de nouvelles fonctionnalités pour améliorer la traçabilité des produits et le suivi des commandes. 2. Optimisation des processus de fabrication : Conception et implémentation d’un algorithme génétique pour optimiser le positionnement des pièces dans les moules, réduisant ainsi les pertes de matériaux et les temps de cycle. Résultats : Amélioration significative de l’efficacité des lignes de production et réduction des coûts associés aux déchets. 3. Automatisation des bancs de test pour prothèses médicales : Développement d’un banc de test automatisé pour les prothèses de hanches, capable de générer des courbes CAM conformes aux normes ISO. Objectifs atteints : Minimisation du “jerk” (accélération brusque) pour garantir des tests fiables et conformes aux standards. Réduction du temps nécessaire aux validations des prototypes grâce à l’automatisation des processus. Compétences développées : Ingénierie digitale : Maîtrise de la structuration des bases de données et des systèmes ERP dans un environnement industriel. Recherche opérationnelle (RO) et optimisation : Utilisation d’algorithmes évolutifs pour résoudre des problèmes complexes liés à la fabrication. Automatisation industrielle : Développement et mise en œuvre de solutions techniques pour améliorer la qualité et l’efficacité des processus de tests. Gestion de projet : Coordination entre les différents services de l’entreprise pour garantir l’alignement des solutions avec les objectifs stratégiques.",
      "description_refined": "",
      "summary": "En tant qu'Ingénieur en Transformation Digitale chez Blispac, j'ai modernisé les processus internes par la digitalisation des bases de données, l'optimisation de la fabrication via un algorithme génétique, et l'automatisation des tests de prothèses. Ces initiatives ont amélioré l'efficacité, réduit les coûts et garanti la conformité aux normes.",
      "bullets": [
        "Optimisé les processus de fabrication avec un algorithme, réduisant les déchets et les temps de cycle.",
        "Automatisé les tests de prothèses, garantissant conformité ISO et réduisant le temps de validation."
      ],
      "weight": 0.6,
      "order": 3,
      "nb_bullets": 2
    },
    {
      "title_raw": "Analyste de Marché",
      "title_refined": "",
      "company_raw": "Total",
      "company_refined": "",
      "location_raw": "Paris, France",
      "location_refined": "",
      "dates_raw": "février 2020 – juillet 2020",
      "dates_refined": "",
      "description_raw": "Au sein de la direction GRP de TotalEnergies, j’ai contribué à l’analyse stratégique des marchés énergétiques mondiaux, en travaillant sur des projets de modélisation et de suivi des dynamiques énergétiques à long terme. Responsabilités principales : 1. Total Energy Outlook : Participation à l’élaboration du Total Energy Outlook, une publication stratégique qui projette l’évolution des marchés énergétiques mondiaux à l’horizon 2050. Travail collaboratif avec une équipe de 10 analystes, combinant expertise sectorielle et modélisation avancée. Production de rapports et d’analyses prospectives pour éclairer les décisions stratégiques du Comex du groupe. 2. Business Reviews : Rédaction et présentation de Business Reviews sur les marchés du gaz naturel liquéfié (GNL) et de l’électricité. Analyse des tendances clés, identification des opportunités, et recommandations pour le développement des activités du groupe. 3. Modélisation et innovation : Développement d’un algorithme en Python, combiné à des pipelines de données, pour suivre en temps réel les tankers GNL à partir des bases de données IHS. Création d’indicateurs inédits, inspirés des méthodologies du marché pétrolier, appliqués pour la première fois au marché GNL : Repositionnement des navires. Analyse des trajets ballast/laden (chargés ou à vide). Utilisation de Pandas pour le traitement des données et de Power BI pour la visualisation, facilitant la prise de décision stratégique. Résultats notables : Mise en place d’une approche innovante pour le suivi des flux de GNL, permettant à TotalEnergies de mieux comprendre et anticiper les dynamiques du marché GNL.",
      "description_refined": "",
      "summary": "En tant qu'analyste de marché chez Total, j'ai contribué à l'analyse stratégique des marchés énergétiques, participé à l'élaboration du Total Energy Outlook, rédigé des Business Reviews sur le GNL et l'électricité, et développé un algorithme en Python pour suivre les tankers GNL, améliorant ainsi la compréhension des dynamiques du marché.",
      "bullets": [
        "Développé un algorithme en Python pour suivre les tankers GNL, améliorant l'analyse des dynamiques.",
        "Produit des rapports stratégiques sur le GNL, éclairant les décisions du Comex de TotalEnergies."
      ],
      "weight": 0.5,
      "order": 4,
      "nb_bullets": 2
    }
  ],
  "education": [
    {
      "degree_raw": "Diplôme d’ingénieur",
      "degree_refined": "",
      "institution_raw": "École des Ponts ParisTech",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2017 – 2021",
      "dates_refined": "",
      "description_raw": "Durant mon cursus à l’École des Ponts ParisTech, j’ai bénéficié d’une formation scientifique et technique de haut niveau, complétée par des enseignements spécialisés en supply chain et en machine learning. 1. Tronc commun scientifique (1ère année) : La première année était dédiée à l’acquisition de bases solides dans les disciplines fondamentales de l’ingénierie : Mathématiques appliquées : approfondissement des concepts d’analyse, d’algèbre linéaire et de probabilités, essentiels pour la modélisation et la résolution de problèmes complexes. Physique : étude des principes de la mécanique, de la thermodynamique et de l’électromagnétisme, permettant de comprendre les phénomènes physiques sous-jacents aux systèmes ingénieriques. Informatique : introduction aux structures de données, aux algorithmes et aux bases de la programmation, compétences cruciales pour le développement d’outils numériques. Sciences de l’ingénieur : notions fondamentales en mécanique des structures et des matériaux, offrant une compréhension des comportements mécaniques des ouvrages et des matériaux utilisés. 2. Spécialisation en Supply Chain et Machine Learning (2ème et 3ème années) : Après le tronc commun, j’ai orienté ma formation vers des domaines spécifiques en choisissant des cours et des projets liés à la supply chain et au machine learning.",
      "description_generated": "Ma formation d'ingénieur m'a permis d'acquérir des compétences solides en mathématiques appliquées, programmation et machine learning, essentielles pour optimiser des plateformes techniques. Mon expertise en data engineering et en développement d'outils numériques me prépare à diriger efficacement une équipe technique et à élaborer des roadmaps produits.",
      "description_refined": "",
      "summary": "Formation d'ingénieur à l'École des Ponts ParisTech, alliant un tronc commun scientifique solide (mathématiques, physique, informatique) à une spécialisation en supply chain et machine learning, développant ainsi des compétences techniques avancées pour résoudre des problèmes complexes dans ces domaines.",
      "weight": 0.8,
      "order": 1,
      "nb_mots": 44
    },
    {
      "degree_raw": "Master 2 en Mathematical Engineering",
      "degree_refined": "",
      "institution_raw": "Politecnico di Milano",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2020 – 2021",
      "dates_refined": "",
      "description_raw": "Durant cette année de spécialisation en ingénierie mathématique, j’ai approfondi mes connaissances en mathématiques appliquées, finance computationnelle, machine learning et supply chain management, tout en apprenant l’italien pour m’intégrer pleinement à l’environnement académique et culturel. Cours principaux suivis : 1. Computational Finance : Ce cours portait sur les méthodes quantitatives avancées pour décrire la dynamique des marchés financiers, évaluer et couvrir des produits dérivés, et résoudre des problèmes d’investissement optimal. 2. Machine Learning : Ce cours proposait une base solide en apprentissage supervisé, apprentissage par renforcement et algorithmes d’extraction de connaissances, avec des applications variées.",
      "description_generated": "Ma formation en ingénierie mathématique m’a permis d’acquérir des compétences avancées en finance computationnelle et machine learning, essentielles pour optimiser la plateforme RAMP. Mon expertise en méthodes quantitatives et algorithmes d’extraction de connaissances est directement applicable à l’analyse de données open-source et à la cartographie concurrentielle.",
      "description_refined": "",
      "summary": "Master 2 en ingénierie mathématique au Politecnico di Milano, axé sur les mathématiques appliquées, la finance computationnelle, le machine learning et la gestion de la chaîne d'approvisionnement. Cours principaux : finance computationnelle et machine learning, avec apprentissage de l'italien pour une intégration culturelle.",
      "weight": 0.9,
      "order": 2,
      "nb_mots": 47
    },
    {
      "degree_raw": "Classe préparatoire scientifique",
      "degree_refined": "",
      "institution_raw": "Collège Stanislas Paris",
      "institution_refined": "",
      "location_raw": "",
      "location_refined": "",
      "dates_raw": "2015 – 2017",
      "dates_refined": "",
      "description_raw": "Durant ces deux années, j’ai suivi une formation académique exigeante en classes préparatoires, préparant aux concours des grandes écoles d’ingénieurs.",
      "description_generated": "Ma formation en classes préparatoires scientifiques m'a permis d'acquérir des compétences solides en analyse de données, en programmation Python et en résolution de problèmes complexes, essentielles pour diriger une équipe technique et optimiser la plateforme RAMP chez Red River West.",
      "description_refined": "",
      "summary": "Formation académique rigoureuse en classe préparatoire scientifique, axée sur la préparation aux concours des grandes écoles d'ingénieurs, acquise sur deux ans au Collège Stanislas Paris.",
      "weight": 0.6,
      "order": 3,
      "nb_mots": 38
    }
  ],
  "competences": {
    "Compétences techniques": [
      "À compléter"
    ]
  },
  "skills_raw": "Alexis possède une expertise approfondie dans plusieurs domaines clés. En tant que Data Engineer et Data Scientist, il maîtrise les technologies Cloud, notamment Google Cloud Platform (GCP) et Amazon Web Services (AWS). Il est également compétent en DevOps, avec une expérience dans la mise en œuvre de pipelines CI/CD et l'utilisation de Docker pour le déploiement d'applications. Ses compétences en MLOps lui permettent d'intégrer des modèles de Machine Learning dans des solutions IT, garantissant leur efficacité et leur scalabilité. En outre, il a développé des compétences en management technique, ayant dirigé des équipes de data engineers, et en optimisation des processus, notamment dans des environnements industriels. Son approche analytique et méthodique, combinée à sa capacité à travailler en équipe, lui permet de mener à bien des projets complexes et stratégiques.",
  "langues": [],
  "hobbies_raw": "En dehors de son expertise technique, Alexis s'intéresse à divers domaines qui enrichissent sa perspective professionnelle. Il est passionné par les nouvelles technologies et l'innovation, ce qui l'incite à se tenir informé des dernières tendances en matière de Cloud et de Data Science. Alexis apprécie également les activités de plein air, telles que la randonnée et le cyclisme, qui lui permettent de se ressourcer et de maintenir un équilibre entre sa vie professionnelle et personnelle. De plus, il s'intéresse à la culture et à l'apprentissage des langues, ayant récemment appris l'italien pour s'intégrer dans un environnement académique international. Ces centres d'intérêt reflètent son ouverture d'esprit et sa volonté d'apprendre continuellement.",
  "hobbies_refined": "",
  "job_raw": "Data Tech Lead\nRed River West est une société de Venture Capital transfrontalière qui aide les startups technologiques\neuropéennes à croître grâce à un soutien financier et à un accompagnement pratique. Ils investissent entre 5 et\n15 millions d'euros dans des startups en Série A ou B pour les aider dans leur expansion internationale, en\nparticulier sur le marché américain.\nPour se concentrer sur les opportunités les plus prometteuses, ils utilisent une plateforme interne qui collecte\net analyse des données sur chaque startup européenne, les transformant en informations exploitables.\nEntreprise classée parmi les 20 meilleurs fonds axés sur les données pendant deux années consécutives aux\ncôtés de leaders du secteur comme Sequoia et a16z.\nLeurs investissements récents incluent DeepOpinion (Agentic AI), Robovision (Computer Vision), The\nExploration Company (Space Tech), etc.\nIls lancent actuellement un nouveau fonds d'investissement où la plupart des décisions seront prises grâce à\ncette plateforme de données et ils recherchent une personne qui leur permettra de faire passer cette\nplateforme au niveau supérieur afin de changer radicalement la façon dont l'investissement en VC se fait dans\nle monde.\nMissions\nVotre objectif sera de diriger une petite équipe technique et d'être responsable de la partie tech & data de\nRAMP, une plateforme de données interne qui aide l'équipe à prioriser et à accéder aux meilleures opportunités\nd'investissement.\nVous serez en charge des décisions techniques, avec une majorité de développement hands-on et vous serez\nun élément clé dans l'élaboration de la roadmap du produit (en collaboration avec le product lead) en\nsuggérant des fonctionnalités et des idées.\nVoici quelques exemples de projets qu’ils ont réalisés jusqu'à présent afin que vous ayez une meilleure idée du\nrôle :\n• Analyse de startups open-source : ils ont construit un module pour collecter et analyser des données\nprovenant de sources de données telles que Github, Huggingface, Hackernews, … afin de trouver les\nprochains succès de l'open-source.\n• Cartographie concurrentielle : ils ont conçu un moyen de trouver les relations de concurrence, les\nmarchés et les industries des entreprises en utilisant les embeddings de LLM et le clustering par\nproximité sémantique.\n• Signalement et sourcing prioritaires : ils ont construit un système pour signaler les startups les plus\nintéressantes et à la croissance la plus rapide à notre équipe d'investissement grâce à des ensembles\nde données sur les startups européennes qu’ils collectent depuis 4 ans.\nStack Technique\n• Base de données : PostgreSQL (Supabase)\n• API : GraphQL via postgREST\n• Pipeline de données : Python & Typescript (scrapers)\n• Cloud : OVH (k8s + VPS)\n• Front-end : Nuxt3 / vue3 & shadcn-vue\n• Autres : GitHub, Docker, Kubernetes\nVotre profil\nMust have\n• Expérience dans un poste de Tech/Data Lead, si possible dans une startup.\n• Excellentes compétences de raisonnement.\n• Python (pandas, numpy, matplotlib, …)\n• Compétences avancées en data engineering (gestion du pipeline de données, SQL, etc.).\n• Compétences avancées en Python (pandas, numpy, matplotlib, …) et Typescript / Javascript.\n• Compétences DevOps (Cloud, Docker, gestion CI/CD, gestion de base du serveur Unix, etc.).\n• Capacité à prendre des responsabilités, des initiatives et à utiliser d'excellentes compétences de\ncompréhension pour développer des algorithmes d'IA et de machine learning ainsi que des approches\nstatistiques.\n• Au moins une connaissance de base des LLM (embeddings, …).\n• Maîtrise de l'anglais.\nNice to have\n• Expérience de travail sur un projet solo/création de produit.\n• Compétences de développement Full-stack Javascript (React, etc.).\n• Connaissance de l'écosystème open-source.\n• Connaissance ou intérêt pour l'écosystème tech & startups / VC.\n• Lecture et rédaction d'une documentation efficace.",
  "job_refined": "Red River West, société de Venture Capital, recherche un Data Tech Lead pour diriger une équipe technique et optimiser sa plateforme interne, RAMP, dédiée à l'analyse des startups européennes. Le candidat sera responsable des décisions techniques, du développement hands-on et de l'élaboration de la roadmap produit. Les projets incluent l'analyse de données open-source et la cartographie concurrentielle. Les compétences requises incluent une expérience en Tech/Data Lead, expertise en Python, data engineering, DevOps, et une connaissance des LLM. Une maîtrise de l'anglais est essentielle. Une expérience en startup et des compétences en développement full-stack sont un plus."
}