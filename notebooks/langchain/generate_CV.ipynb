{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "from langgraph.graph import StateGraph\n",
    "from openai import OpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "# Définition de l'état\n",
    "class CVGenerationState(TypedDict):\n",
    "    profile: dict             # Données du profil\n",
    "    job: dict                # Données sur le job\n",
    "    current_step: str\n",
    "    error: Optional[str]\n",
    "\n",
    "# Exemple de structure pour les données\n",
    "# profile = {\n",
    "#     \"head_raw\": dict,           # Informations de l'en-tête\n",
    "#     \"skills_raw\": dict,         # Compétences\n",
    "#     \"experiences\": List[dict],  # Liste d'expériences\n",
    "#     \"education\": List[dict],    # Liste de formations\n",
    "#     \"hobbies_raw\": dict         # Loisirs\n",
    "# }\n",
    "# job = {\n",
    "#     \"job_posting\": str,     # Fiche de poste\n",
    "#     \"job_summary\": Optional[str] # Résumé de la fiche de poste\n",
    "# }\n",
    "\n",
    "# Structure pour une expérience dans profile[\"experiences\"]\n",
    "# experience = {\n",
    "#     \"titre_raw\": str,\n",
    "#     \"titre_refined\": str,\n",
    "#     \"dates_raw\": str,\n",
    "#     \"dates_refined\": str,\n",
    "#     \"entreprise_raw\": str,\n",
    "#     \"entreprise_refined\": str,\n",
    "#     \"lieu_raw\": str,\n",
    "#     \"lieu_refined\": str,\n",
    "#     \"description\": str,         # Description brute\n",
    "#     \"sumup\": str,              # Résumé\n",
    "#     \"bullets_points\": List[str], # Points clés\n",
    "#     \"poid\": float              # Poids en %\n",
    "# }\n",
    "\n",
    "# Structure pour une formation dans profile[\"education\"]\n",
    "# education = {\n",
    "#     \"titre_raw\": str,\n",
    "#     \"titre_refined\": str,\n",
    "#     \"dates_raw\": str,\n",
    "#     \"dates_refined\": str,\n",
    "#     \"etablissement_raw\": str,\n",
    "#     \"etablissement_refined\": str,\n",
    "#     \"lieu_raw\": str,\n",
    "#     \"lieu_refined\": str,\n",
    "#     \"description\": str,         # Description brute\n",
    "#     \"description_refined\": str, # Description raffinée\n",
    "#     \"sumup\": str,              # Résumé\n",
    "#     \"poid\": float              # Poids en %\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/q2b2x49j16x2jfrqxg8_grdc0000gn/T/ipykernel_14210/2207125639.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de réponse du modèle:\n",
      "Bonjour !\n"
     ]
    }
   ],
   "source": [
    "# Définition du modèle de langage\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Test du modèle\n",
    "test_response = llm.invoke(\"Dis bonjour en français\")\n",
    "print(\"Test de réponse du modèle:\")\n",
    "print(test_response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Chargement des données de test depuis le fichier JSON\n",
    "with open('data_test.json', 'r', encoding='utf-8') as json_file:\n",
    "    test_data = json.load(json_file)\n",
    "\n",
    "# Chargement de la fiche de poste depuis le fichier texte\n",
    "with open('fiche_poste.txt', 'r', encoding='utf-8') as text_file:\n",
    "    job_posting = text_file.read()\n",
    "\n",
    "# Initialisation de l'état avec les données de test et la fiche de poste\n",
    "initial_state = {\n",
    "    \"profile\": {\n",
    "        \"head_raw\": test_data[\"cv_data\"][\"head\"],\n",
    "        \"skills_raw\": test_data[\"cv_data\"][\"skills\"],\n",
    "        \"experiences\": [\n",
    "            {\n",
    "                \"titre_raw\": exp[\"intitule\"],\n",
    "                \"titre_refined\": None,\n",
    "                \"dates_raw\": exp[\"dates\"],\n",
    "                \"dates_refined\": None,\n",
    "                \"entreprise_raw\": exp[\"etablissement\"],\n",
    "                \"entreprise_refined\": None,\n",
    "                \"lieu_raw\": exp[\"lieu\"],\n",
    "                \"lieu_refined\": None,\n",
    "                \"description\": exp[\"description\"],\n",
    "                \"sumup\": None,\n",
    "                \"bullets_points\": [],\n",
    "                \"poid\": None\n",
    "            }\n",
    "            for exp in test_data[\"cv_data\"][\"experiences\"][\"experiences\"]\n",
    "        ],\n",
    "        \"education\": [\n",
    "            {\n",
    "                \"titre_raw\": edu[\"intitule\"],\n",
    "                \"titre_refined\": None,\n",
    "                \"dates_raw\": edu[\"dates\"],\n",
    "                \"dates_refined\": None,\n",
    "                \"etablissement_raw\": edu[\"etablissement\"],\n",
    "                \"etablissement_refined\": None,\n",
    "                \"lieu_raw\": edu[\"lieu\"],\n",
    "                \"lieu_refined\": None,\n",
    "                \"description_raw\": edu[\"description\"],\n",
    "                \"description_refined\": None,\n",
    "                \"sumup\": None,\n",
    "                \"poid\": None\n",
    "            }\n",
    "            for edu in test_data[\"cv_data\"][\"education\"][\"educations\"]\n",
    "        ],\n",
    "        \"hobbies_raw\": test_data[\"cv_data\"][\"hobbies\"]\n",
    "    },\n",
    "    \"job\": {\n",
    "        \"job_posting\": job_posting,\n",
    "        \"job_summary\": None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodes (fonctions de transformation)\n",
    "def summarize_job(state: CVGenerationState) -> CVGenerationState:\n",
    "    response = llm.invoke(\n",
    "        \"Faites un résumé de cette fiche de poste en 100 mots maximum, en incluant les informations principales pour rédiger un CV.\\n\\n\" + \n",
    "        state[\"job\"][\"job_posting\"]\n",
    "    )\n",
    "    state[\"job\"][\"job_summary\"] = response.content.strip()\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Résumé de la fiche de poste - Machine Learning Engineer**\n",
      "\n",
      "Poste : Machine Learning Engineer en CDI, Paris (hybride). Expérience requise : 3+ ans. Salaire : 55k - 75k €. Startup innovante en IA, spécialisée dans le Machine Learning et Deep Learning. Missions : concevoir et déployer des modèles ML, optimiser pipelines de données, développer des API, et collaborer avec des équipes pluridisciplinaires. Compétences requises : maîtrise de Python (TensorFlow, PyTorch), SQL, AWS, GCP, MLOps (MLflow, Kubeflow), et développement (FastAPI, Flask). Diplôme en Informatique ou équivalent souhaité. Environnement dynamique et projets innovants. Postuler à recrutement@startupAI.com.\n"
     ]
    }
   ],
   "source": [
    "initial_state = summarize_job(initial_state)\n",
    "\n",
    "# on affiche le résumé de la fiche de poste\n",
    "print(initial_state[\"job\"][\"job_summary\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résumé de l'expérience : Lors de ma mission chez Renault, j'ai modernisé les équipes de data engineering, piloté la transition vers dbt sur Cloud Run, et introduit des pratiques DevOps. J'ai également développé des outils pour faciliter l'accès aux données et créé des modèles de Machine Learning pour estimer les valeurs résiduelles des véhicules.\n",
      "Résumé de l'expérience : En tant que co-fondateur et CTO de Kadi, j'ai dirigé le développement d'une application mobile innovante pour l'analyse automatique de tickets de caisse, intégrant IA et cloud. J'ai supervisé l'architecture technique, le déploiement sur les stores, et optimisé des pipelines de données, garantissant une expérience utilisateur fluide.\n",
      "Résumé de l'expérience : Dans une entreprise familiale de prothèses médicales, j'ai modernisé les processus internes par la digitalisation des bases de données, l'optimisation de la fabrication via un algorithme génétique, et l'automatisation des tests. Ces projets ont amélioré l'efficacité, réduit les coûts et garanti la conformité aux normes ISO. Compétences développées : ingénierie digitale, optimisation et gestion de projet.\n",
      "Résumé de l'expérience : Au sein de Diagma, j'ai optimisé la supply chain pour des entreprises prestigieuses, notamment Hermès et un laboratoire pharmaceutique, en développant des méthodes de planification et des algorithmes d'optimisation. J'ai également géré un projet de Sale & Leaseback pour un entrepôt, générant des fonds pour des opérations logistiques.\n",
      "Résumé de l'expérience : Au sein de TotalEnergies, j'ai analysé les marchés énergétiques mondiaux, contribuant au Total Energy Outlook et rédigeant des Business Reviews sur le GNL et l'électricité. J'ai développé un algorithme en Python pour suivre les tankers GNL, innovant dans l'analyse des flux et facilitant la prise de décision stratégique.\n",
      "Résumé de l'expérience : Lors de cette mission humanitaire, j'ai géré plus de 100 projets de reconstruction et d'aide au développement dans des zones de conflit, supervisant un budget de 6 millions d'euros. J'ai coordonné des équipes locales, réhabilité des infrastructures essentielles et assuré un suivi administratif, permettant l'accès à l'éducation et à l'énergie renouvelable.\n",
      "Résumé de l'expérience : Cette expérience consiste à optimiser la gestion des entrepôts et à résoudre des problèmes logistiques complexes, notamment le problème de routage des véhicules (Vehicle Routing Problem). L'objectif est d'améliorer l'efficacité des opérations logistiques en minimisant les coûts et en maximisant la satisfaction client.\n"
     ]
    }
   ],
   "source": [
    "def summarize_profile(state: CVGenerationState) -> CVGenerationState:\n",
    "    # Résumer chaque expérience\n",
    "    for experience in state[\"profile\"][\"experiences\"]:\n",
    "        response = llm.invoke(\n",
    "            \"Faites un résumé de cette expérience en 50 mots maximum.\\n\\n\" + \n",
    "            experience[\"description\"]\n",
    "        )\n",
    "        experience[\"sumup\"] = response.content.strip()\n",
    "    \n",
    "    # Résumer chaque formation\n",
    "    for education in state[\"profile\"][\"education\"]:\n",
    "        response = llm.invoke(\n",
    "            \"Faites un résumé de cette formation en 50 mots maximum.\\n\\n\" + \n",
    "            education[\"description_raw\"]\n",
    "        )\n",
    "        education[\"sumup\"] = response.content.strip()\n",
    "    \n",
    "    return state\n",
    "\n",
    "#tester la fonction sur initial_state\n",
    "initial_state = summarize_profile(initial_state)\n",
    "\n",
    "#afficher les résumés\n",
    "for experience in initial_state[\"profile\"][\"experiences\"]:\n",
    "    print(\"Résumé de l'expérience :\", experience.get(\"sumup\", \"Pas de résumé disponible.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résumé de l'éducation : À l’École des Ponts ParisTech, j'ai acquis une formation scientifique et technique de haut niveau, incluant un tronc commun en mathématiques, physique, informatique et sciences de l’ingénieur, suivi d'une spécialisation en supply chain et machine learning durant les deux dernières années.\n",
      "Résumé de l'éducation : Cette année de spécialisation en ingénierie mathématique a permis d'approfondir les mathématiques appliquées, la finance computationnelle, le machine learning et la gestion de la chaîne d'approvisionnement, tout en apprenant l'italien. Les cours principaux incluent la finance computationnelle et le machine learning, avec un accent sur les méthodes quantitatives et les algorithmes.\n",
      "Résumé de l'éducation : J'ai suivi une formation académique rigoureuse en classes préparatoires pendant deux ans, axée sur la préparation aux concours des grandes écoles d'ingénieurs, développant ainsi mes compétences en sciences et en mathématiques. Cette expérience m'a permis d'acquérir une solide base pour poursuivre des études d'ingénierie.\n"
     ]
    }
   ],
   "source": [
    "#afficher les résumés des éducations\n",
    "for education in initial_state[\"profile\"][\"education\"]:\n",
    "    print(\"Résumé de l'éducation :\", education.get(\"sumup\", \"Pas de résumé disponible.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Expériences sélectionnées et leur poids:\n",
      "- Senior Data Scientist chez EY: 40.0%\n",
      "- Co-fondateur et CTO chez Kadi: 30.0%\n",
      "- Ingénieur en Transformation Digitale chez Blispac: 15.0%\n",
      "- Consultant en Stratégie et Supply Chain chez Diagma: Non retenue\n",
      "- Analyste de Marché chez Total: 10.0%\n",
      "- Coordinateur de Projets chez L’Œuvre d’Orient: Non retenue\n",
      "- Consultant junior chez Cdiscount: 5.0%\n"
     ]
    }
   ],
   "source": [
    "def select_experiences(state: CVGenerationState) -> CVGenerationState:\n",
    "    # Préparer le contexte pour l'IA\n",
    "    job_context = state[\"job\"][\"job_summary\"]\n",
    "    experiences_context = \"\\n\".join([\n",
    "        f\"- {exp['titre_raw']} à {exp['lieu_raw']} ({exp['dates_raw']}) chez {exp['entreprise_raw']}: {exp['sumup']}\" \n",
    "        for exp in state[\"profile\"][\"experiences\"]\n",
    "    ])\n",
    "    \n",
    "    # Premier LLM pour sélectionner et pondérer les expériences\n",
    "    prompt = f\"\"\"\n",
    "    En tant qu'expert RH, analysez les expériences du candidat par rapport au poste.\n",
    "    Sélectionnez les expériences les plus pertinentes et attribuez-leur un pourcentage d'importance (la somme doit faire 100%).\n",
    "    Répondez sous forme de texte simple en listant les expériences retenues avec leur pourcentage.\n",
    "    \n",
    "    Poste à pourvoir:\n",
    "    {job_context}\n",
    "    \n",
    "    Expériences du candidat:\n",
    "    {experiences_context}\n",
    "    \"\"\"\n",
    "    \n",
    "    selection_response = llm.invoke(prompt)\n",
    "    selection_text = selection_response.content\n",
    "    \n",
    "    # Pour chaque expérience, demander au second LLM d'extraire le poids\n",
    "    for exp in state[\"profile\"][\"experiences\"]:\n",
    "        exp_prompt = f\"\"\"\n",
    "        Voici la sélection d'expériences pertinentes avec leurs pourcentages:\n",
    "        {selection_text}\n",
    "        \n",
    "        Pour l'expérience suivante, retournez uniquement le pourcentage attribué (juste le nombre), ou \"null\" si elle n'est pas mentionnée:\n",
    "        {exp['titre_raw']} chez {exp['entreprise_raw']}\n",
    "        \"\"\"\n",
    "        \n",
    "        weight_response = llm.invoke(exp_prompt)\n",
    "        try:\n",
    "            weight = float(weight_response.content.strip())\n",
    "            exp[\"poid\"] = weight\n",
    "        except ValueError:\n",
    "            exp[\"poid\"] = None\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Tester la fonction\n",
    "initial_state = select_experiences(initial_state)\n",
    "\n",
    "# Afficher les expériences sélectionnées\n",
    "print(\"\\nExpériences sélectionnées et leur poids:\")\n",
    "for exp in initial_state[\"profile\"][\"experiences\"]:\n",
    "    weight = exp.get(\"poid\")\n",
    "    if weight is not None:\n",
    "        print(f\"- {exp['titre_raw']} chez {exp['entreprise_raw']}: {weight}%\")\n",
    "    else:\n",
    "        print(f\"- {exp['titre_raw']} chez {exp['entreprise_raw']}: Non retenue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Formations sélectionnées et leur poids:\n",
      "- Diplôme d’ingénieur à École des Ponts ParisTech: 40.0%\n",
      "- Master 2 en Mathematical Engineering à Politecnico di Milano: 45.0%\n",
      "- Classe préparatoire scientifique à Collège Stanislas Paris: 15.0%\n"
     ]
    }
   ],
   "source": [
    "def select_education(state):\n",
    "    \"\"\"\n",
    "    Sélectionne et pondère les formations pertinentes pour le poste.\n",
    "    \"\"\"\n",
    "    # Récupérer le contexte\n",
    "    job_context = state[\"job\"][\"job_summary\"]\n",
    "    education_context = \"\\n\".join([f\"{edu['titre_raw']} - {edu['etablissement_raw']} ({edu['dates_raw']}) {edu['lieu_raw']} {edu['sumup']}\" \n",
    "                                 for edu in state[\"profile\"][\"education\"]])\n",
    "    \n",
    "    # Créer le prompt\n",
    "    prompt = f\"\"\"\n",
    "    En tant qu'expert RH, analysez les formations du candidat et sélectionnez celles qui sont les plus pertinentes \n",
    "    pour le poste à pourvoir. Attribuez un pourcentage à chaque formation selon sa pertinence.\n",
    "\n",
    "    Formations du candidat:\n",
    "    {education_context}\n",
    "\n",
    "    Poste à pourvoir:\n",
    "    {job_context}\n",
    "    \"\"\"\n",
    "    \n",
    "    selection_response = llm.invoke(prompt)\n",
    "    selection_text = selection_response.content\n",
    "    \n",
    "    # Pour chaque formation, demander au LLM d'extraire le poids\n",
    "    for edu in state[\"profile\"][\"education\"]:\n",
    "        edu_prompt = f\"\"\"\n",
    "        Voici la sélection de formations pertinentes avec leurs pourcentages:\n",
    "        {selection_text}\n",
    "        \n",
    "        Pour la formation suivante, retournez uniquement le pourcentage attribué (juste le nombre), ou \"null\" si elle n'est pas mentionnée:\n",
    "        {edu['titre_raw']} à {edu['etablissement_raw']}\n",
    "        \"\"\"\n",
    "        \n",
    "        weight_response = llm.invoke(edu_prompt)\n",
    "        try:\n",
    "            weight = float(weight_response.content.strip())\n",
    "            edu[\"poid\"] = weight\n",
    "        except ValueError:\n",
    "            edu[\"poid\"] = None\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Tester la fonction\n",
    "initial_state = select_education(initial_state)\n",
    "\n",
    "# Afficher les formations sélectionnées\n",
    "print(\"\\nFormations sélectionnées et leur poids:\")\n",
    "for edu in initial_state[\"profile\"][\"education\"]:\n",
    "    weight = edu.get(\"poid\")\n",
    "    if weight is not None:\n",
    "        print(f\"- {edu['titre_raw']} à {edu['etablissement_raw']}: {weight}%\")\n",
    "    else:\n",
    "        print(f\"- {edu['titre_raw']} à {edu['etablissement_raw']}: Non retenue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights(state, threshold=10):\n",
    "    \"\"\"\n",
    "    Ajuste les poids des expériences et formations :\n",
    "    - Met à 0 les poids inférieurs ou égaux au seuil \n",
    "    - Rééquilibre les poids restants pour garder une somme de 100%\n",
    "    \"\"\"\n",
    "    # Ajuster les poids des expériences\n",
    "    if \"profile\" in state and \"experiences\" in state[\"profile\"]:\n",
    "        # Mettre 0 pour les poids None ou non numériques\n",
    "        for exp in state[\"profile\"][\"experiences\"]:\n",
    "            try:\n",
    "                if exp.get(\"poid\") is None or not isinstance(exp.get(\"poid\"), (int, float)):\n",
    "                    exp[\"poid\"] = 0\n",
    "            except:\n",
    "                exp[\"poid\"] = 0\n",
    "\n",
    "        exp_weights = [exp[\"poid\"] for exp in state[\"profile\"][\"experiences\"]]\n",
    "        total_weight = sum(w for w in exp_weights if w > threshold)\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            for exp in state[\"profile\"][\"experiences\"]:\n",
    "                if exp[\"poid\"] <= threshold:\n",
    "                    exp[\"poid\"] = 0\n",
    "                else:\n",
    "                    exp[\"poid\"] = round((exp[\"poid\"] / total_weight) * 100)\n",
    "\n",
    "    # Ajuster les poids des formations\n",
    "    if \"profile\" in state and \"education\" in state[\"profile\"]:\n",
    "        # Mettre 0 pour les poids None ou non numériques\n",
    "        for edu in state[\"profile\"][\"education\"]:\n",
    "            try:\n",
    "                if edu.get(\"poid\") is None or not isinstance(edu.get(\"poid\"), (int, float)):\n",
    "                    edu[\"poid\"] = 0\n",
    "            except:\n",
    "                edu[\"poid\"] = 0\n",
    "\n",
    "        edu_weights = [edu[\"poid\"] for edu in state[\"profile\"][\"education\"]]\n",
    "        total_weight = sum(w for w in edu_weights if w > threshold)\n",
    "        \n",
    "        if total_weight > 0:\n",
    "            for edu in state[\"profile\"][\"education\"]:\n",
    "                if edu[\"poid\"] <= threshold:\n",
    "                    edu[\"poid\"] = 0\n",
    "                else:\n",
    "                    edu[\"poid\"] = round((edu[\"poid\"] / total_weight) * 100)\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Tester la fonction\n",
    "initial_state = adjust_weights(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bullet points générés pour chaque expérience:\n",
      "\n",
      "None chez None:\n",
      "• Optimisé les pipelines de données en concevant et déployant une solution dbt sur Cloud Run, améliorant la qualité et la rapidité des processus de transformation des données, approuvée par la direction technique.\n",
      "• Dirigé une équipe de 5 data engineers pour moderniser les pratiques de data engineering, intégrant des méthodologies agiles et des outils modernes, ce qui a permis une adoption généralisée de dbt comme standard au sein de Renault.\n",
      "\n",
      "None chez None:\n",
      "• Conçu et déployé une application mobile innovante sur GCP, intégrant des modèles de Machine Learning pour l'analyse automatique de tickets de caisse, validée par des utilisateurs sur les principales plateformes mobiles.\n",
      "• Optimisé des pipelines de données évolutifs en intégrant des pratiques MLOps, garantissant la scalabilité et la haute disponibilité des services, tout en améliorant la performance des modèles de détection d'objets en production.\n",
      "\n",
      "None chez None:\n",
      "• Conçu et déployé un algorithme génétique pour optimiser le positionnement des pièces dans les moules, entraînant une réduction de 20% des pertes de matériaux et une amélioration de l'efficacité des lignes de production.\n",
      "• Digitalisé les processus internes en refondant les bases de données SQL et en intégrant de nouvelles fonctionnalités dans l'ERP, ce qui a permis d'améliorer la traçabilité des produits et de réduire le temps de traitement des commandes de 30%.\n"
     ]
    }
   ],
   "source": [
    "def generate_experience_bullets(state):\n",
    "    \"\"\"\n",
    "    Génère des bullet points pour chaque expérience en fonction de leur poids\n",
    "    \"\"\"\n",
    "    if \"profile\" not in state or \"experiences\" not in state[\"profile\"]:\n",
    "        return state\n",
    "    \n",
    "    for exp in state[\"profile\"][\"experiences\"]:\n",
    "        # Vérifier que poid existe et n'est pas None avant de l'utiliser\n",
    "        if not exp.get(\"poid\"):\n",
    "            continue\n",
    "            \n",
    "        # Calculer le nombre de bullet points en fonction du poids\n",
    "        nb_bullets = max(2, min(6, round(exp[\"poid\"] / 20)))\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        En tant qu'expert RH, générez {nb_bullets} bullet points percutants qui mettent en valeur cette expérience \n",
    "        professionnelle par rapport au poste visé.\n",
    "        \n",
    "        Chaque bullet point doit:\n",
    "        - Commencer par un verbe d'action fort\n",
    "        - Être concis et impactant\n",
    "        - Mettre en avant les réalisations concrètes\n",
    "        - Être adapté au poste visé\n",
    "        \n",
    "        Répondez au format JSON suivant:\n",
    "        {{\n",
    "            \"bullet_points\": [\n",
    "                \"Premier bullet point\",\n",
    "                \"Deuxième bullet point\",\n",
    "                etc.\n",
    "            ]\n",
    "        }}\n",
    "        \n",
    "        Poste visé (résumé):\n",
    "        {state[\"job\"][\"job_summary\"]}\n",
    "        \n",
    "        Expérience à décrire:\n",
    "        {exp[\"description\"]}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke(input=prompt, response_format={\"type\": \"json_object\"})\n",
    "        bullets = json.loads(response.content)\n",
    "        \n",
    "        # Ajouter les bullet points à l'expérience\n",
    "        exp[\"bullets_points\"] = bullets[\"bullet_points\"]\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Tester la fonction\n",
    "initial_state = generate_experience_bullets(initial_state)\n",
    "\n",
    "# Afficher les bullet points générés\n",
    "print(\"\\nBullet points générés pour chaque expérience:\")\n",
    "for exp in initial_state[\"profile\"][\"experiences\"]:\n",
    "    if exp.get(\"poid\", 0) > 0:\n",
    "        print(f\"\\n{exp['titre_refined']} chez {exp['entreprise_refined']}:\")\n",
    "        for bullet in exp[\"bullets_points\"]:\n",
    "            print(f\"• {bullet}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptions raffinées pour chaque formation:\n",
      "\n",
      "Diplôme d’ingénieur - École des Ponts ParisTech:\n",
      "Formation à l’École des Ponts ParisTech : expertise en machine learning, optimisation de données et modélisation avancée.\n",
      "\n",
      "Master 2 en Mathematical Engineering - Politecnico di Milano:\n",
      "Formation en ingénierie mathématique : compétences avancées en machine learning et finance computationnelle, essentielles pour le poste.\n",
      "\n",
      "Classe préparatoire scientifique - Collège Stanislas Paris:\n",
      "Formation rigoureuse en classes préparatoires, développant compétences analytiques et techniques essentielles pour le Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "def generate_education_description(state):\n",
    "    \"\"\"\n",
    "    Génère une description raffinée pour chaque formation en fonction de leur poids\n",
    "    \"\"\"\n",
    "    if \"profile\" not in state or \"education\" not in state[\"profile\"]:\n",
    "        return state\n",
    "    \n",
    "    for edu in state[\"profile\"][\"education\"]:\n",
    "        if edu.get(\"poid\", 0) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Adapter la longueur de la description en fonction du poids\n",
    "        nb_mots = max(15, min(50, round(edu[\"poid\"] / 10)))\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        En tant qu'expert RH, générez une description percutante de cette formation\n",
    "        qui met en valeur sa pertinence par rapport au poste visé.\n",
    "        \n",
    "        La description doit:\n",
    "        - Être concise (environ {nb_mots} mots)\n",
    "        - Mettre en avant les compétences acquises\n",
    "        - Souligner les réalisations académiques importantes\n",
    "        - Être adaptée au poste visé\n",
    "        \n",
    "        Poste visé (résumé):\n",
    "        {state[\"job\"][\"job_summary\"]}\n",
    "        \n",
    "        Formation à décrire:\n",
    "        {edu[\"description_raw\"]}\n",
    "        \"\"\"\n",
    "        \n",
    "        response = llm.invoke(input=prompt)\n",
    "        \n",
    "        # Ajouter la description raffinée à la formation\n",
    "        edu[\"description_refined\"] = response.content\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Tester la fonction\n",
    "initial_state = generate_education_description(initial_state)\n",
    "\n",
    "# Afficher les descriptions générées\n",
    "print(\"\\nDescriptions raffinées pour chaque formation:\")\n",
    "for edu in initial_state[\"profile\"][\"education\"]:\n",
    "    if edu.get(\"poid\", 0) > 0:\n",
    "        print(f\"\\n{edu['titre_raw']} - {edu['etablissement_raw']}:\")\n",
    "        print(edu[\"description_refined\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "État actuel:\n",
      "{\n",
      "  \"profile\": {\n",
      "    \"head_raw\": {\n",
      "      \"general_title\": \"Data Engineer / Data Scientist | Expert Cloud et Data. Alexis de Monts est un ingénieur des Ponts et Chaussées, spécialisé dans la transformation numérique des entreprises grâce à ses compétences en Data Science. Avec une formation scientifique généraliste et une spécialisation en Data Science au Politecnico di Milano, il se concentre sur l'intégration de solutions Cloud et d'algorithmes de Machine Learning dans des systèmes informatiques complexes. Son expérience inclut la création d'un Data Hub pour Renault et le développement d'applications mobiles innovantes.\",\n",
      "      \"email\": \"alexis.demonts.s@gmail.com\",\n",
      "      \"phone\": \"07 81 37 86 80\",\n",
      "      \"name\": \"Alexis de Monts\"\n",
      "    },\n",
      "    \"skills_raw\": {\n",
      "      \"description\": \"Alexis possède une expertise approfondie dans plusieurs domaines clés. En tant que Data Engineer et Data Scientist, il maîtrise les technologies Cloud, notamment Google Cloud Platform (GCP) et Amazon Web Services (AWS). Il est également compétent en DevOps, avec une expérience dans la mise en œuvre de pipelines CI/CD et l'utilisation de Docker pour le déploiement d'applications. Ses compétences en MLOps lui permettent d'intégrer des modèles de Machine Learning dans des solutions IT, garantissant leur efficacité et leur scalabilité. En outre, il a développé des compétences en management technique, ayant dirigé des équipes de data engineers, et en optimisation des processus, notamment dans des environnements industriels. Son approche analytique et méthodique, combinée à sa capacité à travailler en équipe, lui permet de mener à bien des projets complexes et stratégiques.\"\n",
      "    },\n",
      "    \"experiences\": [\n",
      "      {\n",
      "        \"titre_raw\": \"Senior Data Scientist\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"février 2023 – présent\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"EY\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"Ville de Paris, Île-de-France, France\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Mission chez Renault (FLMDH – Fleet Management Data Hub). Dans le cadre de cette mission stratégique, j’ai joué un rôle central dans la modernisation et la structuration des équipes data engineering de Renault, tout en pilotant des projets clés pour accompagner la transition du groupe vers le leasing et le véhicule électrique. Contributions principales : 1. Cadrage et pilotage des équipes Data Engineer : Management d’une équipe de 5 data engineers, en assurant le cadrage des activités, la définition des priorités, et la montée en compétence des membres sur de nouveaux outils et pratiques. Mise en place d’une méthodologie de travail structurée, alignée sur les objectifs stratégiques du groupe et intégrant des outils modernes pour améliorer la productivité et la collaboration. 2. Transition vers dbt sur Cloud Run : Conception et déploiement d’une solution innovante pour dbt, utilisant un service dédié sur Cloud Run, une première dans l’écosystème Renault. Création from scratch d’un repository Git, d’une pipeline CI/CD, et d’un service Cloud Run, permettant : La gestion efficace des modèles dbt. La standardisation des pratiques data au sein de l’équipe. Collaboration avec les équipes de sécurité informatique pour garantir la conformité aux normes du groupe, et présentation des avantages de cette solution à la direction. 3. Transformation DevOps : Introduction de pratiques DevOps modernes dans un environnement encore en transition vers le cloud. Migration des processus traditionnels de data transformation vers une solution scalable et performante intégrant dbt, contribuant à l’amélioration des performances et à la réduction des temps de traitement. Formation et accompagnement des équipes internes pour assurer une adoption réussie de cette nouvelle architecture. 4. Sujets stratégiques : Talk to Data (Gemini) : Développement d’un assistant conversationnel pour démocratiser l’accès aux données auprès des équipes métiers, facilitant ainsi des décisions basées sur les données. Estimation des Valeurs Résiduelles (VR) : Création de modèles Machine Learning pour estimer les valeurs résiduelles des véhicules en leasing, en tenant compte des spécificités des véhicules électriques et thermiques. Résultats obtenus : Réussite de la transition des équipes DevOps Renault vers une solution dbt sur Cloud Run, approuvée par les équipes de sécurité et la direction technique. Amélioration notable de la qualité et de la rapidité des pipelines de données grâce à une infrastructure moderne et un workflow CI/CD automatisé. Adoption généralisée de dbt comme standard pour les projets de transformation des données, permettant une collaboration plus fluide entre les équipes. Accélération de l’intégration des données critiques pour les décisions stratégiques liées au leasing et à l’électrification. Compétences développées : Management technique : Encadrement et montée en compétence d’une équipe data engineering. DevOps et MLOps : Mise en œuvre de pipelines CI/CD modernes et transition vers des solutions cloud natives. Collaboration interservices : Coordination entre équipes métiers, sécurité informatique, et data engineers pour faire avancer des projets stratégiques complexes.\",\n",
      "        \"sumup\": \"Lors de ma mission chez Renault, j'ai modernisé les équipes de data engineering, piloté la transition vers dbt sur Cloud Run, et introduit des pratiques DevOps. J'ai également développé des outils pour faciliter l'accès aux données et créé des modèles de Machine Learning pour estimer les valeurs résiduelles des véhicules.\",\n",
      "        \"bullets_points\": [\n",
      "          \"Optimisé les pipelines de données en concevant et déployant une solution dbt sur Cloud Run, améliorant la qualité et la rapidité des processus de transformation des données, approuvée par la direction technique.\",\n",
      "          \"Dirigé une équipe de 5 data engineers pour moderniser les pratiques de data engineering, intégrant des méthodologies agiles et des outils modernes, ce qui a permis une adoption généralisée de dbt comme standard au sein de Renault.\"\n",
      "        ],\n",
      "        \"poid\": 47\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Co-fondateur et CTO\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"décembre 2022 – présent\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"Kadi\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"En tant que co-fondateur et CTO de Kadi, j’ai dirigé le développement d’une application mobile innovante permettant l’analyse automatique de tickets de caisse. Mon rôle a couvert à la fois la définition de l’architecture technique et la mise en œuvre de solutions basées sur l’intelligence artificielle et le cloud. Responsabilités principales : 1. Conception et déploiement de l’application mobile : Définition de l’architecture technique de l’application, en choisissant des technologies adaptées aux besoins : Flutter pour le front-end et Google Cloud Platform (GCP) pour l’infrastructure back-end. Supervision du développement, des tests et du déploiement de l’application sur le Google Play Store et l’Apple Store, garantissant une expérience utilisateur fluide. 2. Développement d’une IA pour l’analyse des tickets de caisse : Entraînement et déploiement d’un modèle Faster R-CNN pour détecter automatiquement les tickets de caisse dans des images et extraire les données pertinentes. Mise en production sur Google App Engine, assurant une scalabilité et une haute disponibilité des services. 3. Création de workflows de données évolutifs : Mise en place de pipelines de données automatisés à l’aide de Cloud Functions, Firestore, et BigQuery pour stocker, traiter et analyser les données utilisateur. Intégration des bonnes pratiques MLOps, incluant la surveillance des performances, la gestion des versions du modèle et l’automatisation des mises à jour. 4. Optimisation des pipelines de bout en bout : Développement de pipelines fiables et performants pour traiter les données en temps réel, de la réception des images au stockage et à la restitution des résultats aux utilisateurs. Résultats : Déploiement réussi de l’application en version bêta, validée par une communauté d’utilisateurs sur les deux principales plateformes mobiles. Compétences développées : Leadership technique : Coordination d’une équipe technique et supervision des choix stratégiques en matière de technologies. Machine Learning appliqué : Développement de solutions basées sur des modèles de détection d’objets et leur mise en production dans des environnements cloud. Cloud computing : Expertise dans l’utilisation de GCP pour développer des systèmes évolutifs et performants. MLOps : Application des principes de DevOps au machine learning pour garantir la fiabilité et la pérennité des modèles en production. Développement mobile : Maîtrise de Flutter et des exigences spécifiques au déploiement sur Google Play et Apple Store. Impact et résultats : Création d’une application mobile intuitive répondant à un besoin concret : simplifier la gestion des tickets de caisse pour les utilisateurs. Déploiement d’une infrastructure cloud robuste, capable de gérer des flux de données en temps réel avec une latence minimale. Mise en œuvre d’un modèle d’IA performant et innovant pour extraire automatiquement des informations structurées à partir de données brutes.\",\n",
      "        \"sumup\": \"En tant que co-fondateur et CTO de Kadi, j'ai dirigé le développement d'une application mobile innovante pour l'analyse automatique de tickets de caisse, intégrant IA et cloud. J'ai supervisé l'architecture technique, le déploiement sur les stores, et optimisé des pipelines de données, garantissant une expérience utilisateur fluide.\",\n",
      "        \"bullets_points\": [\n",
      "          \"Conçu et déployé une application mobile innovante sur GCP, intégrant des modèles de Machine Learning pour l'analyse automatique de tickets de caisse, validée par des utilisateurs sur les principales plateformes mobiles.\",\n",
      "          \"Optimisé des pipelines de données évolutifs en intégrant des pratiques MLOps, garantissant la scalabilité et la haute disponibilité des services, tout en améliorant la performance des modèles de détection d'objets en production.\"\n",
      "        ],\n",
      "        \"poid\": 35\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Ingénieur en Transformation Digitale\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"février 2022 – septembre 2022\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"Blispac\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"Balagny-sur-Thérain (60)\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Au sein de cette entreprise familiale spécialisée dans la production de prothèses médicales, j’ai conduit plusieurs projets stratégiques visant à moderniser et optimiser les processus internes. Responsabilités principales : 1. Digitalisation de l’entreprise : Refonte et structuration des bases de données existantes en SQL pour centraliser et sécuriser les informations critiques. Développement d’outils facilitant l’accès aux données pour les différents départements de l’entreprise. Mise à jour de l’ERP : Analyse des besoins métiers et adaptation de l’ERP pour mieux répondre aux exigences opérationnelles. Intégration de nouvelles fonctionnalités pour améliorer la traçabilité des produits et le suivi des commandes. 2. Optimisation des processus de fabrication : Conception et implémentation d’un algorithme génétique pour optimiser le positionnement des pièces dans les moules, réduisant ainsi les pertes de matériaux et les temps de cycle. Résultats : Amélioration significative de l’efficacité des lignes de production et réduction des coûts associés aux déchets. 3. Automatisation des bancs de test pour prothèses médicales : Développement d’un banc de test automatisé pour les prothèses de hanches, capable de générer des courbes CAM conformes aux normes ISO. Objectifs atteints : Minimisation du “jerk” (accélération brusque) pour garantir des tests fiables et conformes aux standards. Réduction du temps nécessaire aux validations des prototypes grâce à l’automatisation des processus. Compétences développées : Ingénierie digitale : Maîtrise de la structuration des bases de données et des systèmes ERP dans un environnement industriel. Recherche opérationnelle (RO) et optimisation : Utilisation d’algorithmes évolutifs pour résoudre des problèmes complexes liés à la fabrication. Automatisation industrielle : Développement et mise en œuvre de solutions techniques pour améliorer la qualité et l’efficacité des processus de tests. Gestion de projet : Coordination entre les différents services de l’entreprise pour garantir l’alignement des solutions avec les objectifs stratégiques.\",\n",
      "        \"sumup\": \"Dans une entreprise familiale de prothèses médicales, j'ai modernisé les processus internes par la digitalisation des bases de données, l'optimisation de la fabrication via un algorithme génétique, et l'automatisation des tests. Ces projets ont amélioré l'efficacité, réduit les coûts et garanti la conformité aux normes ISO. Compétences développées : ingénierie digitale, optimisation et gestion de projet.\",\n",
      "        \"bullets_points\": [\n",
      "          \"Conçu et déployé un algorithme génétique pour optimiser le positionnement des pièces dans les moules, entraînant une réduction de 20% des pertes de matériaux et une amélioration de l'efficacité des lignes de production.\",\n",
      "          \"Digitalisé les processus internes en refondant les bases de données SQL et en intégrant de nouvelles fonctionnalités dans l'ERP, ce qui a permis d'améliorer la traçabilité des produits et de réduire le temps de traitement des commandes de 30%.\"\n",
      "        ],\n",
      "        \"poid\": 18\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Consultant en Stratégie et Supply Chain\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"septembre 2021 – février 2022\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"Diagma\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"Paris, France\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Au sein de Diagma, j’ai participé à plusieurs missions stratégiques et opérationnelles pour des entreprises de renom, avec un focus sur l’optimisation de la supply chain et la résolution de problématiques complexes via des approches quantitatives. Missions principales : 1. Optimisation de la production pour Hermès (cuves de parfum) : Développement et mise en œuvre de nouvelles méthodes de planification de production, adaptées aux contraintes spécifiques des processus industriels de fabrication des parfums. Refonte des algorithmes d’optimisation linéaire en nombres entiers pour : Déterminer les batches optimaux en fonction des volumes et des délais. Identifier et atténuer les goulots d’étranglement dans le processus de production. Résultats : Amélioration de l’efficacité des chaînes de production et meilleure allocation des ressources. 2. Projet AZAP – Logiciel de prévision : Analyse des données de demande pour un grand distributeur, en intégrant les variations saisonnières dans les modèles de prévision. Étude et application des fonctionnalités du logiciel AZAP, spécialisé dans la prévision et la planification avancée. Résultats : Amélioration de la précision des prévisions et optimisation des niveaux de stock. 3. Opération de Sale & Leaseback pour un entrepôt logistique : Gestion d’une opération stratégique pour un entrepôt de 70 000 m², valorisé à 60 millions d’euros. Étapes clés du projet : Préparation de l’information memorandum pour présenter l’entrepôt aux investisseurs potentiels. Mise en concurrence d’une trentaine de banques d’investissement pour maximiser la valeur de l’actif. Suivi et coordination des différentes étapes de la vente jusqu’à sa finalisation. Résultats : Vente réussie, générant des fonds pour réinvestir dans les opérations logistiques du client. 4. Optimisation de la production pour un laboratoire pharmaceutique : Restructuration des méthodes de planification pour maximiser la productivité et minimiser les délais de production. Application d’algorithmes d’optimisation linéaire et de simulations pour améliorer les processus de production. Résultats : Réduction des coûts de production et amélioration des délais de mise sur le marché. Compétences développées : Optimisation quantitative : Expertise dans l’utilisation d’algorithmes d’optimisation linéaire et de techniques de modélisation pour résoudre des problèmes complexes. Gestion de projet : Capacité à piloter des projets stratégiques de grande envergure, en collaboration avec des parties prenantes variées.\",\n",
      "        \"sumup\": \"Au sein de Diagma, j'ai optimisé la supply chain pour des entreprises prestigieuses, notamment Hermès et un laboratoire pharmaceutique, en développant des méthodes de planification et des algorithmes d'optimisation. J'ai également géré un projet de Sale & Leaseback pour un entrepôt, générant des fonds pour des opérations logistiques.\",\n",
      "        \"bullets_points\": [],\n",
      "        \"poid\": 0\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Analyste de Marché\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"février 2020 – juillet 2020\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"Total\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"Paris, France\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Au sein de la direction GRP de TotalEnergies, j’ai contribué à l’analyse stratégique des marchés énergétiques mondiaux, en travaillant sur des projets de modélisation et de suivi des dynamiques énergétiques à long terme. Responsabilités principales : 1. Total Energy Outlook : Participation à l’élaboration du Total Energy Outlook, une publication stratégique qui projette l’évolution des marchés énergétiques mondiaux à l’horizon 2050. Travail collaboratif avec une équipe de 10 analystes, combinant expertise sectorielle et modélisation avancée. Production de rapports et d’analyses prospectives pour éclairer les décisions stratégiques du Comex du groupe. 2. Business Reviews : Rédaction et présentation de Business Reviews sur les marchés du gaz naturel liquéfié (GNL) et de l’électricité. Analyse des tendances clés, identification des opportunités, et recommandations pour le développement des activités du groupe. 3. Modélisation et innovation : Développement d’un algorithme en Python, combiné à des pipelines de données, pour suivre en temps réel les tankers GNL à partir des bases de données IHS. Création d’indicateurs inédits, inspirés des méthodologies du marché pétrolier, appliqués pour la première fois au marché GNL : Repositionnement des navires. Analyse des trajets ballast/laden (chargés ou à vide). Utilisation de Pandas pour le traitement des données et de Power BI pour la visualisation, facilitant la prise de décision stratégique. Résultats notables : Mise en place d’une approche innovante pour le suivi des flux de GNL, permettant à TotalEnergies de mieux comprendre et anticiper les dynamiques du marché GNL.\",\n",
      "        \"sumup\": \"Au sein de TotalEnergies, j'ai analysé les marchés énergétiques mondiaux, contribuant au Total Energy Outlook et rédigeant des Business Reviews sur le GNL et l'électricité. J'ai développé un algorithme en Python pour suivre les tankers GNL, innovant dans l'analyse des flux et facilitant la prise de décision stratégique.\",\n",
      "        \"bullets_points\": [],\n",
      "        \"poid\": 0\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Coordinateur de Projets\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"juin 2019 – février 2020\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"L’Œuvre d’Orient\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"Erbil, Irak\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Durant cette mission humanitaire, j’ai été en charge de la gestion de projets sur le terrain, supervisant les activités de reconstruction et d’aide au développement dans des zones touchées par la guerre et l’instabilité. Responsabilités principales : 1. Gestion de projet : Supervision d’un portefeuille de plus de 100 projets humanitaires, représentant un budget annuel de 6 millions d’euros. Suivi rigoureux des projets en lien avec le Centre de crise et de soutien du Ministère des Affaires étrangères français (MAE). Coordination avec les donateurs, partenaires locaux, et acteurs internationaux pour garantir l’atteinte des objectifs dans les délais impartis. 2. Reconstruction et développement : Reconstruction d’infrastructures essentielles : écoles, hôpitaux, installations d’eau potable, systèmes solaires, et autres structures vitales. Réhabilitation de villages pour permettre le retour des populations déplacées dans des conditions dignes et sécurisées. 3. Encadrement d’équipe : Management d’une équipe locale de 10 personnes, composée d’ingénieurs, de techniciens, et de responsables de terrain. Formation et accompagnement des équipes pour renforcer les compétences locales et assurer la pérennité des projets. 4. Suivi administratif et financier : Gestion des budgets, rédaction de rapports financiers, et audits de conformité pour garantir une utilisation optimale des fonds. Reporting régulier aux bailleurs de fonds et aux partenaires, mettant en avant les progrès réalisés et les défis rencontrés. Résultats notables : Reconstruction et réouverture de plusieurs écoles, permettant à des centaines d’enfants de retrouver un accès à l’éducation. Installation de systèmes solaires pour alimenter les villages isolés en énergie renouvelable.\",\n",
      "        \"sumup\": \"Lors de cette mission humanitaire, j'ai géré plus de 100 projets de reconstruction et d'aide au développement dans des zones de conflit, supervisant un budget de 6 millions d'euros. J'ai coordonné des équipes locales, réhabilité des infrastructures essentielles et assuré un suivi administratif, permettant l'accès à l'éducation et à l'énergie renouvelable.\",\n",
      "        \"bullets_points\": [],\n",
      "        \"poid\": 0\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Consultant junior\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"octobre 2018 – février 2019\",\n",
      "        \"dates_refined\": null,\n",
      "        \"entreprise_raw\": \"Cdiscount\",\n",
      "        \"entreprise_refined\": null,\n",
      "        \"lieu_raw\": \"\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description\": \"Optimisation d’entrepôts et résolution de problèmes logistiques complexes (Vehicle Routing Problem).\",\n",
      "        \"sumup\": \"Cette expérience consiste à optimiser la gestion des entrepôts et à résoudre des problèmes logistiques complexes, notamment le problème de routage des véhicules (Vehicle Routing Problem). L'objectif est d'améliorer l'efficacité des opérations logistiques en minimisant les coûts et en maximisant la satisfaction client.\",\n",
      "        \"bullets_points\": [],\n",
      "        \"poid\": 0\n",
      "      }\n",
      "    ],\n",
      "    \"education\": [\n",
      "      {\n",
      "        \"titre_raw\": \"Diplôme d’ingénieur\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"2017 – 2021\",\n",
      "        \"dates_refined\": null,\n",
      "        \"etablissement_raw\": \"École des Ponts ParisTech\",\n",
      "        \"etablissement_refined\": null,\n",
      "        \"lieu_raw\": \"\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description_raw\": \"Durant mon cursus à l’École des Ponts ParisTech, j’ai bénéficié d’une formation scientifique et technique de haut niveau, complétée par des enseignements spécialisés en supply chain et en machine learning. 1. Tronc commun scientifique (1ère année) : La première année était dédiée à l’acquisition de bases solides dans les disciplines fondamentales de l’ingénierie : Mathématiques appliquées : approfondissement des concepts d’analyse, d’algèbre linéaire et de probabilités, essentiels pour la modélisation et la résolution de problèmes complexes. Physique : étude des principes de la mécanique, de la thermodynamique et de l’électromagnétisme, permettant de comprendre les phénomènes physiques sous-jacents aux systèmes ingénieriques. Informatique : introduction aux structures de données, aux algorithmes et aux bases de la programmation, compétences cruciales pour le développement d’outils numériques. Sciences de l’ingénieur : notions fondamentales en mécanique des structures et des matériaux, offrant une compréhension des comportements mécaniques des ouvrages et des matériaux utilisés. 2. Spécialisation en Supply Chain et Machine Learning (2ème et 3ème années) : Après le tronc commun, j’ai orienté ma formation vers des domaines spécifiques en choisissant des cours et des projets liés à la supply chain et au machine learning.\",\n",
      "        \"description_refined\": \"Formation à l’École des Ponts ParisTech : expertise en machine learning, optimisation de données et modélisation avancée.\",\n",
      "        \"sumup\": \"À l’École des Ponts ParisTech, j'ai acquis une formation scientifique et technique de haut niveau, incluant un tronc commun en mathématiques, physique, informatique et sciences de l’ingénieur, suivi d'une spécialisation en supply chain et machine learning durant les deux dernières années.\",\n",
      "        \"poid\": 40\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Master 2 en Mathematical Engineering\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"2020 – 2021\",\n",
      "        \"dates_refined\": null,\n",
      "        \"etablissement_raw\": \"Politecnico di Milano\",\n",
      "        \"etablissement_refined\": null,\n",
      "        \"lieu_raw\": \"\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description_raw\": \"Durant cette année de spécialisation en ingénierie mathématique, j’ai approfondi mes connaissances en mathématiques appliquées, finance computationnelle, machine learning et supply chain management, tout en apprenant l’italien pour m’intégrer pleinement à l’environnement académique et culturel. Cours principaux suivis : 1. Computational Finance : Ce cours portait sur les méthodes quantitatives avancées pour décrire la dynamique des marchés financiers, évaluer et couvrir des produits dérivés, et résoudre des problèmes d’investissement optimal. 2. Machine Learning : Ce cours proposait une base solide en apprentissage supervisé, apprentissage par renforcement et algorithmes d’extraction de connaissances, avec des applications variées.\",\n",
      "        \"description_refined\": \"Formation en ingénierie mathématique : compétences avancées en machine learning et finance computationnelle, essentielles pour le poste.\",\n",
      "        \"sumup\": \"Cette année de spécialisation en ingénierie mathématique a permis d'approfondir les mathématiques appliquées, la finance computationnelle, le machine learning et la gestion de la chaîne d'approvisionnement, tout en apprenant l'italien. Les cours principaux incluent la finance computationnelle et le machine learning, avec un accent sur les méthodes quantitatives et les algorithmes.\",\n",
      "        \"poid\": 45\n",
      "      },\n",
      "      {\n",
      "        \"titre_raw\": \"Classe préparatoire scientifique\",\n",
      "        \"titre_refined\": null,\n",
      "        \"dates_raw\": \"2015 – 2017\",\n",
      "        \"dates_refined\": null,\n",
      "        \"etablissement_raw\": \"Collège Stanislas Paris\",\n",
      "        \"etablissement_refined\": null,\n",
      "        \"lieu_raw\": \"\",\n",
      "        \"lieu_refined\": null,\n",
      "        \"description_raw\": \"Durant ces deux années, j’ai suivi une formation académique exigeante en classes préparatoires, préparant aux concours des grandes écoles d’ingénieurs.\",\n",
      "        \"description_refined\": \"Formation rigoureuse en classes préparatoires, développant compétences analytiques et techniques essentielles pour le Machine Learning.\",\n",
      "        \"sumup\": \"J'ai suivi une formation académique rigoureuse en classes préparatoires pendant deux ans, axée sur la préparation aux concours des grandes écoles d'ingénieurs, développant ainsi mes compétences en sciences et en mathématiques. Cette expérience m'a permis d'acquérir une solide base pour poursuivre des études d'ingénierie.\",\n",
      "        \"poid\": 15\n",
      "      }\n",
      "    ],\n",
      "    \"hobbies_raw\": {\n",
      "      \"description\": \"En dehors de son expertise technique, Alexis s'intéresse à divers domaines qui enrichissent sa perspective professionnelle. Il est passionné par les nouvelles technologies et l'innovation, ce qui l'incite à se tenir informé des dernières tendances en matière de Cloud et de Data Science. Alexis apprécie également les activités de plein air, telles que la randonnée et le cyclisme, qui lui permettent de se ressourcer et de maintenir un équilibre entre sa vie professionnelle et personnelle. De plus, il s'intéresse à la culture et à l'apprentissage des langues, ayant récemment appris l'italien pour s'intégrer dans un environnement académique international. Ces centres d'intérêt reflètent son ouverture d'esprit et sa volonté d'apprendre continuellement.\"\n",
      "    }\n",
      "  },\n",
      "  \"job\": {\n",
      "    \"job_posting\": \"iche de Poste – Machine Learning Engineer\\n\\n📍 Localisation : Paris, France (Hybrid)\\n\\n📅 Type de Contrat : CDI\\n\\n📊 Expérience : 3+ ans\\n\\n💰 Salaire : 55k - 75k € selon expérience\\n\\n💼 Secteur : Tech / IA / Data\\n\\n\\n🚀 À propos de nous\\n\\nNous sommes une startup innovante spécialisée dans l’intelligence artificielle et le traitement des données à grande échelle. Nous développons des solutions de Machine Learning et Deep Learning pour optimiser la prise de décision et automatiser des processus complexes dans divers secteurs (finance, retail, industrie, santé…).\\n\\nNotre équipe est composée de passionnés de l’IA et de la data, avec une forte culture d’innovation et un environnement de travail dynamique.\\n\\n🎯 Missions\\n\\nEn tant que Machine Learning Engineer, vous aurez pour mission de :\\n\\t•\\tConcevoir, entraîner et déployer des modèles de Machine Learning et Deep Learning adaptés aux besoins métier.\\n\\t•\\tTravailler avec des data scientists pour industrialiser les modèles et les intégrer aux produits en production.\\n\\t•\\tOptimiser les pipelines de données et les modèles pour améliorer la performance et la scalabilité.\\n\\t•\\tDévelopper des API et des microservices pour exposer les modèles ML en production.\\n\\t•\\tMonitorer et améliorer la qualité des modèles en continu (MLOps).\\n\\t•\\tCollaborer avec les équipes DevOps et Data Engineering pour assurer la robustesse des infrastructures ML.\\n\\t•\\tDocumenter et partager les bonnes pratiques en ingénierie ML.\\n\\n🛠️ Stack Technique\\n    •\\tLangages : Python (TensorFlow, PyTorch, Scikit-Learn), SQL\\n    •\\tCloud & DevOps : AWS (SageMaker, Lambda, S3), GCP, Docker, Kubernetes\\n    •\\tBig Data : Spark, Dask, Apache Beam\\n    •\\tMLOps : MLflow, DVC, Kubeflow, Airflow\\n    •\\tDéveloppement : FastAPI, Flask, Git, CI/CD\\n\\n🎓 Profil recherché\\n\\t•\\tDiplôme en Informatique, Mathématiques appliquées, Intelligence Artificielle ou équivalent.\\n\\t•\\tExpérience confirmée en développement et déploiement de modèles ML en production.\\n\\t•\\tBonne maîtrise des pipelines de données et des architectures distribuées.\\n\\t•\\tExpérience avec les outils MLOps et le déploiement de modèles à l’échelle.\\n\\t•\\tCapacité à collaborer avec des équipes pluridisciplinaires (Data Scientists, DevOps, Software Engineers).\\n\\t•\\tEsprit analytique, curiosité et passion pour l’IA et la Data Science.\\n\\n💡 Pourquoi nous rejoindre ?\\n\\n✅ Projets innovants en IA et ML\\n✅ Culture d’entreprise orientée innovation et partage\\n✅ Technologies modernes et stack technique avancée\\n✅ Équipe bienveillante et dynamique\\n✅ Flexibilité (hybride) et package attractif\\n\\n📩 Comment postuler ?\\n\\nEnvoyez votre CV et une courte présentation à recrutement@startupAI.com. 🚀\",\n",
      "    \"job_summary\": \"**Résumé de la fiche de poste - Machine Learning Engineer**\\n\\nPoste : Machine Learning Engineer en CDI, Paris (hybride). Expérience requise : 3+ ans. Salaire : 55k - 75k €. Startup innovante en IA, spécialisée dans le Machine Learning et Deep Learning. Missions : concevoir et déployer des modèles ML, optimiser pipelines de données, développer des API, et collaborer avec des équipes pluridisciplinaires. Compétences requises : maîtrise de Python (TensorFlow, PyTorch), SQL, AWS, GCP, MLOps (MLflow, Kubeflow), et développement (FastAPI, Flask). Diplôme en Informatique ou équivalent souhaité. Environnement dynamique et projets innovants. Postuler à recrutement@startupAI.com.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nÉtat actuel:\")\n",
    "print(json.dumps(initial_state, indent=2, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
